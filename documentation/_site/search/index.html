<!DOCTYPE html>
<html lang="en}"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Search | POMS Guide</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Search" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The Production Operations Management System (POMS) is a project designed to provide a service to assist production teams and analysis groups of experiments in their MC production and DATA processing. As the quantity of data originated by the running experiments greatly increases, the ability of simplifying the steps in data processing and management has become more and more appealing to the users. POMS provides a web service interface that enables automated jobs submission on distributed resources according to customers’ requests and subsequent monitoring and recovery of failed submissions, debugging and record keeping. The ultimate goal is the most efficient utilization of all computing resources available to experiments, while providing a simple and transparent interface between users and the complexity of the grid. POMS runs behind a web service interface that provides both interactive pages to the users, and a REST interfaces to scripts that interact with it. This means that experiments can use POMS through their web browser to configure and run their production code, or they can use the poms_client and poms_jobsub_wrapper tools to submit jobs through a command line and have POMS tracking, debugging and monitoring them." />
<meta property="og:description" content="The Production Operations Management System (POMS) is a project designed to provide a service to assist production teams and analysis groups of experiments in their MC production and DATA processing. As the quantity of data originated by the running experiments greatly increases, the ability of simplifying the steps in data processing and management has become more and more appealing to the users. POMS provides a web service interface that enables automated jobs submission on distributed resources according to customers’ requests and subsequent monitoring and recovery of failed submissions, debugging and record keeping. The ultimate goal is the most efficient utilization of all computing resources available to experiments, while providing a simple and transparent interface between users and the complexity of the grid. POMS runs behind a web service interface that provides both interactive pages to the users, and a REST interfaces to scripts that interact with it. This means that experiments can use POMS through their web browser to configure and run their production code, or they can use the poms_client and poms_jobsub_wrapper tools to submit jobs through a command line and have POMS tracking, debugging and monitoring them." />
<link rel="canonical" href="https://fermitools.github.io/poms/docs//search/" />
<meta property="og:url" content="https://fermitools.github.io/poms/docs//search/" />
<meta property="og:site_name" content="POMS Guide" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Search" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"The Production Operations Management System (POMS) is a project designed to provide a service to assist production teams and analysis groups of experiments in their MC production and DATA processing. As the quantity of data originated by the running experiments greatly increases, the ability of simplifying the steps in data processing and management has become more and more appealing to the users. POMS provides a web service interface that enables automated jobs submission on distributed resources according to customers’ requests and subsequent monitoring and recovery of failed submissions, debugging and record keeping. The ultimate goal is the most efficient utilization of all computing resources available to experiments, while providing a simple and transparent interface between users and the complexity of the grid. POMS runs behind a web service interface that provides both interactive pages to the users, and a REST interfaces to scripts that interact with it. This means that experiments can use POMS through their web browser to configure and run their production code, or they can use the poms_client and poms_jobsub_wrapper tools to submit jobs through a command line and have POMS tracking, debugging and monitoring them.","headline":"Search","url":"https://fermitools.github.io/poms/docs//search/"}</script>
<!-- End Jekyll SEO tag -->
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
  <script src="/assets/poms_docs.js"></script>
  <link rel="shortcut icon" href="#">
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="/assets/styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css"><link type="application/atom+xml" rel="alternate" href="https://fermitools.github.io/poms/docs//feed.xml" title="POMS Guide" /></head>
<header><nav id="toc">
    <center>
        <img class="site-logo" src="https://fermitools.github.io/poms/docs//docs/images/poms.jpg"/>
    </center>
    <div class="navigation-area">
        <h3>Navigation</h3>
        <div class="search-container">
            <input type="text" id="search" placeholder="Search...">
            <span class="search-icon"><i class="fas fa-search"></i></span>
        </div>        
    </div>
    <div class="container">
        <ul id="main-menu">
            
                
                    <li class="menu-item " >
                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/backwards_compatibility/index.html">Backwards Compatibility</a>
                        
                    </li>
                
            
                
                    <li class="menu-item " >
                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/campaign_editor/index.html">Campaign Editor</a>
                        
                    </li>
                
            
                
                    <li class="menu-item " >
                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/client_documentation/index.html">Client Documentation</a>
                        
                    </li>
                
            
                
                    <li class="menu-item has-submenu" >
                        <a class="menu-link open" href="https://fermitools.github.io/poms/docs/experimenters_corner/index.html">Experimenters Corner</a>
                        
                            <ul>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/calendar_help/index.html">Calendar Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/campaign_deps_help/index.html">Campaign Deps Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/campaign_edit_help/index.html">Campaign Edit Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/campaign_info_help/index.html">Campaign Info Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/campaign_layer_info/index.html">Campaign Layer Info</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/campaign_sheet_help/index.html">Campaign Sheet Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/campaign_task_files_help/index.html">Campaign Task Files Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/campaign_time_bars_help/index.html">Campaign Time Bars Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/dashboard_help/index.html">Dashboard Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item has-submenu">
                                        <a class="menu-link open" href="https://fermitools.github.io/poms/docs/experimenters_corner/data_dispatcher/index.html">Data Dispatcher</a>
                                        
                                            <ul>
                                                
                                                    <li class="menu-item"><a class="menu-link" href="https://fermitools.github.io/poms/docs/experimenters_corner/data_dispatcher/environment_setup/index.html">Environment Setup</a></li>
                                                
                                                    <li class="menu-item"><a class="menu-link" href="https://fermitools.github.io/poms/docs/experimenters_corner/data_dispatcher/poms_campaign_setup/index.html">POMS Campaign_setup</a></li>
                                                
                                                    <li class="menu-item"><a class="menu-link" href="https://fermitools.github.io/poms/docs/experimenters_corner/data_dispatcher/split_types_and_data_dispatcher_fields/index.html">Split Types and Data Dispatcher Fields</a></li>
                                                
                                                    <li class="menu-item"><a class="menu-link" href="https://fermitools.github.io/poms/docs/experimenters_corner/data_dispatcher/tracking_submissions/index.html">Tracking Submissions</a></li>
                                                
                                            </ul>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/dataset_split_types/index.html">Dataset Split Types</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/edit_users_help/index.html">Edit Users Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/editing_job_types/index.html">Editing Job Types</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/experiment_edit_help/index.html">Experiment Edit Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/fife_newsletter_article/index.html">Fife Newsletter Article</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/file_info_by_submission_help/index.html">File Info By Submission Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/generic_edit_help/index.html">Generic Edit Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/getting_more_memory_in_recovery_jobs/index.html">Getting More Memory In Recovery Jobs</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/held_launches_help/index.html">Held Launches Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/how_to_make_snow_request_for_poms/index.html">How To Make Snow Request For Poms</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/how_to_use_poms/index.html">How To Use Poms</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/job_efficiency_histo_help/index.html">Job Efficiency Histo Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/job_file_contents_help/index.html">Job File Contents Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/job_table_help/index.html">Job Table Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/launch_campaign_help/index.html">Launch Campaign Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/launch_jobs_help/index.html">Launch Jobs Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/launch_template_edit_help/index.html">Launch Template Edit Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/list_generic_help/index.html">List Generic Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/membership_help/index.html">Membership Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/oidc_auth_help/index.html">Oidc Auth Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/protoDUNE/index.html">Protodune</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/raw_tables_help/index.html">Raw Tables Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/sample_workflow/index.html">Sample Workflow</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/schedule_launch_help/index.html">Schedule Launch Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/search_tags_help/index.html">Search Tags Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/show_campaigns_help/index.html">Show Campaigns Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/submission_details_help/index.html">Submission Details Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/triage_job_help/index.html">Triage Job Help</a>
                                        
                                    </li>
                                
                                    <li class="menu-item ">
                                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/experimenters_corner/tutorial_outline/index.html">Tutorial Outline</a>
                                        
                                    </li>
                                
                            </ul>
                        
                    </li>
                
            
                
                    <li class="menu-item " >
                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/frequently_asked_questions/index.html">Frequently Asked Questions</a>
                        
                    </li>
                
            
                
                    <li class="menu-item " >
                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/glossary/index.html">Glossary</a>
                        
                    </li>
                
            
                
                    <li class="menu-item " >
                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/gui_workflow_editor_user_guide/index.html">Gui Workflow Editor User Guide</a>
                        
                    </li>
                
            
                
            
                
                    <li class="menu-item " >
                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/launch_config_file_templates/index.html">Launch Config File Templates</a>
                        
                    </li>
                
            
                
                    <li class="menu-item " >
                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/release_notes/index.html">Release Notes</a>
                        
                    </li>
                
            
                
                    <li class="menu-item " >
                        <a class="menu-link " href="https://fermitools.github.io/poms/docs/user_documentation/index.html">User Documentation</a>
                        
                    </li>
                
            
        </ul>
    </div>
</nav>


  </header>
  <body>
    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        
<div class="breadcrumbs"></div>
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Search</h1>
  </header>

  <div class="post-content">
    <div id="search-results">
    <h3 id="query_string"></h3>
    <ul>
        
            
                <li class="searchable-post" data-search-text="-----


  404

  Page not found :(
  The requested page could not be found.

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/404.html"></a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Release Notes-----
  v4_1_1    
      Notable Features
      Bugs Fixed
      New Features
      New Tasks and Ideas
    
  
  v4_1    
      Major Features
      Bugs Fixed
      New Features
      New Tasks
    
  
  v4_0_2    
      Major Features
      Bugs Fixed
      New Features/Tasks
    
  
  v4_0_1    
      Major Features
      Bugs Fixed
      New Features/Tasks
    
  
  v4_0_0    
      Major Features
      Bugs Fixed
      New Features/Tasks
    
  
  v3_1_0    
      Bugs Fixed
      New Features/Tasks
    
  
  v3_0_0    
      Bugs Fixed
      New Features/Tasks
    
  
  v2_3_0    
      Bugs Fixed
      New Features
      Improvements
    
  
  v2_2_1    
      Bugs Fixed
    
  
  v2_2_0    
      New Features
      Improvements
      Bugs Fixed
    
  
  v2_1_2    
      Bugs Fixed
    
  
  v2_1_1    
      New Features
      Improvements
      Bugs Fixed
    
  
  v2_1_0    
      New Features
      Improvements
      Bugs Fixed
    
  
  v2_0_1    
      New Features
      Improvements
      Bugs Fixed
    
  
  v2_0_0    
      New Features
      Improvements
      Bugs Fixed
    
  
  v1_0_1    
      New Features
      Bugs Fixed
    
  
  v1_1_0    
      New Features
      Improvements
      Bugs Fixed
    
  
  v1_0_0a    
      New Features
      Improvements
      Bugs Fixed
    
  
  v1_0_0    
      New Features
      Improvements
      Bugs Fixed
    
  
  b0_5    
      New Features
      Bugs Fixed
    
  

include_toc: true
show_comments: false
toc: true
—

  TOC

v4_1_1
Notable Features

  Within a campaign, any stage can be configured to wait for approval  before being submitted.
  Documentation has been greatly enhanced to provide greater details.  For example stages have been enlarged with a more complete description.
  Each webpage is now linked to a wiki help page.   The link is shown as a question mark at the top of the page.


Bugs Fixed

  Bug #22243: kill submission, etc. get worker jobs, but not dagman, also should set submission to “Removed”
  Bug #22234: Transition to Located on single file projects
  Bug #22162: cloning sample files needs to fix experiment= and actually fix the name
  Bug #22073: Job submitted, failed to run successfully but POMS so no data file generated, but POMS marked them located
  Bug #22064: editing a login/setup entry for analysis campaign requires an experiment hostname
  Bug #22047: upload_file page without choosing file
  Bug #22012: Got errors while killing a running job


New Features

  Feature #22110: create a pause/hold feature while submitting stages in the same campaign
  Feature #22090: poms_client API for Campaign Stage Submissions
  Feature #22026: show_campaigns and list_campaigns
  Feature #22021: Special use of UPLOADS env var for Analysis users
  Feature #22015: Override-able parameters in the gui editor: Database Change
  Feature #21955: poms client submit a job by campaign
  Feature #21953: poms_client add function upload ini should return the campaign and all stage ids/names
  Feature #21952: poms_client make_poms_call
  Feature #22177: poms_client APIs get job_type_snapshot_obj and login_setup_snap_obj by their IDs
  Feature #22026: show_campaigns and list_campaigns
  Feature #21993: create a campaign from ini
  Feature #22176: POMS Client API for campaign names and stage names giving campaignid and.or stage_id
  Feature #22213: extend poms_client campaign_stage_submissions function to take as argumrents ‘tdays’, ‘tmin’ and ‘tmax’
  Feature #22035: poms_client: remove functions needed


New Tasks and Ideas

  Task #21967: poms_client: clean up the user interface to reflect the change of campaign and campaign stage definition
  Idea #22046: How to handle dataset for intermediate stages
  Task #21555: Add link to Campaign Documentation on POMS home page
  Task #21477: Add one info page where multiple ? are present
  Task #21046: Document Handling custom placeholders in param overrides
  Task #19708: Documentation: Recovery Campaigns
  Task #19707: Documentation: Launch Script


v4_1

Major Features

  Added support for Analysis users.  We are testing this in production before distributing across experiments.


Bugs Fixed

  Bug #20619: Need a check on campaign stage edits
  Bug #20865: GUI Campaign editor “Double click to open” box remains too long.
  Bug #20904: Tags form fails creating new tags.
  Bug #20978: Need time range limit in poms_submission_agent.py…
  Bug #21045: Campaign stage form - two links point to same plot.
  Bug #21341: INC000000993451 - Users crashing when changing campaigns - but logged into different experiment.
  Bug #21380: campaign_task_files - the previous/next day links are not working
  Bug #21401: Need to add knowledge of experiment in campaign_time_bars .
  Bug #21402: When using form from Compose campaign stage, no error reported if stage has no login setup or job type.
  Bug #21413: datasets generated for dependent job launches should be more restrictive.
  Bug #21605: Kill / hold / release jobs doesn’t hold right on DAGs (RITM0761732)
  Bug #21707: Campaign editor: cs_split_type does not save changes
  Bug #21775: Deleting tagged campaign fails


New Features

  Feature #19128: Revise user and experiment forms to follow user entry procedures.
  Feature #20213: Multiparameter workflow
  Feature #20217: Tool to interactively setup the same environement as a job launch
  Feature #20234: Report failure of a POMS campaign submission in the offline dashboard of experiments.
  Feature #20244: Maintain campaign_stage_n_active dataset
  Feature #20590: Workflow editor, internal structure
  Feature #20763: Make status (i.e. for SubmissionHistory) a vocab table with ids ordered(New, LaunchFailed, Idle, Running, Held, Failed, Completed, Located)
  Feature #21103: Submissions: Code update
  Feature #20771: Add button for custom recovery launches somewhere…
  Feature #20852: add time frame for stage plots
  Feature #20881: set X509_USER_PROXY auomatically for production jobs
  Feature #20944: Make a tag selection searchable.
  Feature #20993: Add a launch campaign button from Campaign page
  Feature #21109: Expose POMS “hidden” data to users
  Feature #21207: Need recovery launch info in .ini file dump, workflow editor, etc.
  Feature #21208: Need recovery launch info in .ini file dump
  Feature #21209: need recovery launch info in campaign editor on job type
  Feature #21210: Add recovery launch bits to ini file uploader.
  Feature #21282: Campaign Editor: Cloning Stages
  Feature #21411: Delete a job in New status
  Feature #21420: Update poms_client to pass POMS4_XXX parameters to jobsub
  Feature #21445: Request RITM0739824: login_setup and job_type are not highlighted in aqua for the campaign stage.
  Feature #21502: Analysis user support
  Feature #21503: File upload facility for analysis users
  Feature #21504: Sandbox directory creator
  Feature #21505: Modify launch code for analysis sandboxes
  Feature #21506: Amend login/setup for Analysis jobs
  Feature #21593: restrict login/setup launch_host and launch_user for analysis users
  Feature #21507: Add a file / proxy upload script to poms_client
  Feature #21508: Modify launch code to hold launches for analysis users without a proxy
  Feature #21613: Replace list of launch logs with submission list in campaign info page
  Feature #21701: About Campaign Editor.
  Feature #21702: About Campaign Editor.


New Tasks

  Task #19706: Documentation: Launch Template
  Task #20598: Split type plugins
  Task #20995: Add check on campaign stage edits
  Task #20996: Add check on campaign stage edits
  Task #21102: Submissions: Database changes
  Task #20855: Search Box - Campaigns and stages forms
  Task #20887: Obtain coordinators from FERRY.
  Task #20902: Move active flag from stages to campaigns
  Task #20941: Store nodes positions in campaign editor.
  Task #21187: Add campaign name and stage name to form produced by list_launch_file.
  Task #21372: Testing campaigns show up in uboone production reports
  Task #21476: type fields in campaigns, campaign_stage
  Task #21436: Documentation: Experiment version number
  Task #21486: Revise to the submission time bars page
  Task #21509: Convert Coordinator to Superuser
  Task #21510: Convert the submission time bars to tables
  Task #21523: Make Campaign field readonly when editing an existing stage.
  Task #21526: Rename function to compose job type.
  Task #21697: About Uploaded Files option.
  Task #21698: About Uploaded Files page.
  Task #21699: About Launch button.


v4_0_2

Major Features


  Added new split type for draining datasets.
  Added button to force submissions to move to located.


Bugs Fixed


  Bug #21336 wrapup_tasks using wrong file pattern,,,
  Bug #21296 Provide user understandable data for a Campaign Stage Launch 404 Error.
  Bug #21167 Corrected dependent/recovery jobs to store and show correct user.
  Bug #21166 Fixed recovery bugs caused by invalid dimension query.


New Features/Tasks


  Feature #21318 Button to force submissions to move to Located
  Feature #20243 Added byexistingruns split type.


v4_0_1

Major Features


  Backward compatibility documentation provided “here”:https://cdcvs.fnal.gov/redmine/projects/prod_mgmt_db/wiki/Release_v400Backward_Compatibility-_What_You_need_to_know
  Campaign Editor has had minor improvements for easier usage.
  Campaign page active/inactive setting now works.
  Tagging campaigns is working again.


Bugs Fixed


  Bug #20916 Spaces in stage/job type/login setup names
  Bug #20917 Multiline launch scripts in login/setup forms
  Bug #20935 Fix code that handles Tags
  Bug #20936 Campaign Editor: prevent linking the campaign defaults to the stage


New Features/Tasks


  Feature #20938 Campaign Editor improvements
  Feature #20939 Documentation: talk about ‘backward compatibility’ for new release


v4_0_0

Major Features

Bugs Fixed


  Bug #19699 Unregistered user logging in causes stack dump.
  Bug #19745 Aliases fail when shibboleth session has not be established.


New Features/Tasks


  Documentation Revised - Written for new users
  Fully integrated with Fifemon
  Experiment’s Analysis users can login and view production
  .ini files can be exported, edited and uploaded
  NEW GUI Campaign Editor - View/edit entire campaign.
  Feature #20654 Previous Users should be able to view anything in their experiment
  Feature #20673 Upgrade POMS to python 3.6
  Task #19187 Tutorials for experiment’s production teams.
  Task #19276 Give Landscape the info of exp for the specific CAMPAIGN_ID, Campaign NAME, user running campaign
  Task #19694 Documentation: Overview Documentation
  Task #19696 Documentation: Production Processing High Level View
  Task #19701 Documentation: Requirements for Creating a Campaign
  Task #19698 Documentation: Adding a New Experiment or User
  Task #19702 Documentation: Creating a Campaign - Details
  Task #19710 Documentation: Campaign Actions
  Task #19770 Documentation: Cloning
  Task #19758 Create Campaign Stage Dependency Ordering
  Task #19263 Webpage in POMS to build the workflow
  Task #19761 Test Workflow Editor
  Task #19837 Fix up prototype workflow editor
  Task #19931 Automatically add users to poms_announce
  Task #20037 Table/field ids renaming
  Task #20041 Conversion of POMS to Fifemon
  Task #20042 Conversion: Database Changes
  Task #20043 Conversion: Eliminate scraping applications
  Task #20045 Conversion: Convert reports/plots to use elasticsearch
  Task #20101 Rename the tables and fields and update all source code to match functional names.
  Task #20225 Update the Show Campaigns (tags) form to use a table.
  Task #20226 Revise the main page.


v3_1_0

Bugs Fixed


  Bug #19445 SAM project link not working in POMS - Opened SNOW ticket INC000000935297
  Bug #19624 Whitespace confuses split_types code
  Bug #19922 bulk update is locking to heavily…
  Bug #19852 Stack dumps when deleting a job type
  Bug #19704 Jump to Campaign from the Campaign Stage Info only works for Active campings.
  Bug #19647 The link to the SNOW downtime page appears different from the other two under external links in POMS menu (blue characters and not centered).
  Bug #19624 Whitespace confuses split_types code


New Features/Tasks


  Feature #19504 Dependencies should accept SAM metadata query bits, not just file pattern.
  Feature #19434 Use the Exp Software Version to tell POMS which version of the experiment’s code would be loaded in the job.
  Feature #19418 Add link to the SNOW outage calendar under external links menu
  Feature #19324 add completed jobs index
  Feature #19199 Add “Test mode” to the Campaign stage.
  Feature #17852 Get downtimes from SNOW downtime calendar
  Task #19256 Fix .ssh/config for the round-robin alias


v3_0_0

Bugs Fixed


  Bug #18627: submission time bars prev/next doesn’t work for tag= instead of campaign_id=.
  Bug #18833: Restore the fuzzy search for users.
  Bug #18918: “Tag/Untag Campaigns” action not working (as expected?)..
  Bug #18945: addusers.py does not update POMS when VOMS data for existing experimenter changes.
  Bug #19029: addusers.py seems to switch to inactive users with production role.
  Bug #19055: People with role production in VOMS have analysis role in POMS.
  Bug #19139: Failed jobs classified as located in dbrailsf_gen_poms_test campaign stage.
  Bug #19142: Kill submission campaign not working.
  Bug #19192: Test button not working on just-added launch templates.
  Bug #19338: declared_files_agent is starving…Bug #19368: release job is killing instead..


New Features/Tasks


  Feature #16747: Show dependency, if any, in the campaign info page.
  Feature #18074: Last-modified info on campaigns, etc.
  Feature #18123: Need a way to reset, step back, split dataset iterators…
  Feature #18830: Role pull down menu for User Authorization and add security check.
  Feature #19297: Add “Config File Templates” in the POMS navigation menu.
  Feature #19024: addusers.py development.
  Feature #19120: DNS round-robin alias dune-computing.fnal.gov as a job launch node in POMS.
  Task #18871: Integration database.
  Task #19298: Add configuration file templates to the “Config File Templates” sub-menu.
  Task #18911: Provide a launch config template to interface POMS to the experiments’ configurations, job submission and executable.
  Task #18988: Download/upload whole campaign/workflow to/from file.
  Task #19088: Add coordinators to each of the experiments according to the partial list in the description (Will be update as the info come).
  Task #19198: Change “Submit” button in all Configure Work with “Save”


v2_3_0

Bugs Fixed


  Bug #18176: Don’t fail if session_experiment is not set.
  Bug #18194: Hold reason not being propagated to database.
  Bug #18300: Deal with files with unknown status in project summary/datasets for “delivered” file stats.
  Bug #18361: Button to reset split dataset sequence in a campaign.
  Bug #18388: Held jobs that are removed should be marked as Removed, not Completed.


New Features


  Feature #12195: Test button for launch template, campaign definition.
  Feature #17741: Add “Tag/UnTag Campaign”.
  Feature #17779: Add “campaign_type” field to “campaigns” table &amp;model.
  Feature #17894: More datasets splitting types.
  Feature #17895: Make links on campaign_info page links to last active week of campaign, not current week.
  Feature #17931: Add “HOLD/RELEASE Jobs button”.
  Feature #17934: Add “HOLD/RELEASE Launches button(s)”.
  Feature #18365: Add a byrun split type.
  Feature #18731: Track who launches/submits jobs including the cron launcher.


Improvements


  Feature #17859: Define roles into POMS.
  Task #18772: Change “root” from role to flag.


v2_2_1

Bugs Fixed


  Bug #17638: Deadlock errors in bulk_update, with Nova’s 30k jobs queued.
  Bug #17641: Memory overrun from jobsub_q_scraper -* uwsgi on pomsgpvm02.
  Bug #17684: Crontab code is generating wrong path to the launcher again.
  Bug #17685: Bulk_update jobs doesn’t collapse task_ids in task_updates.


v2_2_0

New Features


  Feature #17599: Additional histograms of job information – run-time, transfer-time, etc.
  Feature #17349: job reporters should split updates into multiple queues by task_id (odd/even, modulo 3, etc).
  Feature #17324: Have in the main campaign list webpage only basic information.
  Feature #17323: New campaign should invalidate the cache.
  Feature #17188: Select bunch of campaings and mark them inactive capability.
  Feature #17187: Filter to order campaign list.
  Feature #17026: Color code numbers in job tables.
  Feature #17025: Add more file totals to show_campaigns – we have pending files, but should have total in datasets, delivered, etc. rollups.
  Feature #16869: Interface to SNOW request and incident ticket.
  Feature #16782: Interface to ECL.
  Feature #16709: Link to some Kibana stats for each campaign.


Improvements


  RITM0582786 from Alex. Run time and file transfer time histograms like job efficiency histogram.
  RITM0583138 from Alex. Implement the capability to select a bunch of campaigns from the list displayed and mark them inactive.


Bugs Fixed


  Bug #17532: Unknown error when clicking Config work/compose Job type, the create a new job type.
  Bug #17525: Inactive campaigns (No activity in the latest x 7? days) shown as active.
  Bug #17524: Unknown error when clicking Campaign Data/campaign Stages to delete.
  Bug #17522: unknown error when clicking on configure work/Compose launch template to duplicating with the existing name.
  Bug #17506: limit launch template hosts to have experiment name in them.
  Bug #17327: bulk_update_jobs is cpu_bound and not keeping up.
  Bug #17284: Spreadsheet report page choked on large Campaigns.
  Bug #17264: project descriptions not going in	Marc Mengel.
  Bug #17259: Delete function not working in the web application.
  Bug #17258: Strip spaces from fields before storing - causing apparent duplication issues.
  Bug #17204: Have the full string “Launch Template” readable from the POMS campaign info.
  Bug #17200: New campaigns don’t appear in the list.
  Bug #15181: Campaign Layer Sheet - - cannot click through.


v2_1_2

Bugs Fixed


  Bug #17028. Proxy Error while loading POMS pages is appearing again. NOvA is experiencing this problem and opened a ticket (RITM0575905).
    
      Bug #16989. Rework show_campaigns.
    
  
  Bug #17024. Fix headers in show_campaigns.
  Bug #17027. Unsual Completed but not Located job counts for NOvA.
  Bug #17085. Use N/A to indicate when information in a certain table cell is not provided.
    
      Bug #17086.  Use N/A instead of -1 in poms/campaign_sheet pending column.
    
  


v2_1_1

New Features


  Feature #14287 More detailed overall campaign-at-a-glance status page


Improvements


  Request #15560Alex H. suggests to have a 1-week time window in the default page of active campaigns and mark those with 1 week of inactivity as inactive with the default time window equal the duration of the campaign.


Bugs Fixed


  Bug #11963. Accessing development POMS application on fermicloud045, occasionally I see this error message:
    
      The proxy server received an invalid response from an upstream server.
      The proxy server could not handle the request GET /poms/campaign_sheet.
    
  
  Bug #15042: ‘IntegrityError’ is not defined
  Bug #15043: The link on the number for Total Completed jobs on poms/show_campaigns page returns an empty set.
  Bug #15545: Non exit code showing.  Not reporting an exit code via ifdh log, or the joblog_scraper agent being down/out of memory when the job was running.  Now we may get the exitcode, etc. from the joblog parser
  Bug #15547: In cut versions, we print a “fatal” git error trying to get the version from git.
  Bug #15646 fts_scanner error on startup
  Bug #16403 Changed tag to version
  Bug #16405 Info in a time window are not correct.


v2_1_0

New Features


  Non-new features in this version.


Improvements


  Feature #16067: Use “streaming” mode in queries to reduce memory usage
  Feature #15058. We need several software test-stands:
  Feature #15144: Add mock webservice for testing agents
  Feature #15208: add tests to test/testUtilsPOMS.py
  Feature #15317: Add more tests to test/test_JobsPOMS.py
  Feature #15342: Add tests to test/test_AccessPOMS.py
  Feature #15343: add more tests to test/test_CalendarPOMS.py
  Feature #15344: Add more tests to test/test_CampaignsPOMS.py
  Feature #15345: Add mor tests to test/test_FilesPOMS.py
  Feature #15346: Add more tests to test/test_TagsPOMS.py
  Feature #15347: test_TriagePOMS.py	Closed	Marc Mengel
  Feature #15348: Add test to stand up a cherrypy instace and fetch one each
  Feature #15624: Add username column to experimenters table to fix VOMS import


Bugs Fixed

  Bug #15751. The Tag is not working. This was discovered by Margarita when she did the test of this module.


v2_0_1

New Features


  Non-new features in this version. This is a bug release.


Improvements

  Feature #15945: Change “Campaign Layers” to “Campaign Stages” in page templates
  Feature #15946: Hide unused files-per-job fields
  Feature #15948: Change name to Campaign Layers
  Feature #15949: Splitted menu into: “Campaign info” and “Configure Work”
  Feature #15950: Change the order of the steps into “Configure Work” menu in to make the options more intuitive.


Bugs Fixed


  Bug #15866: Moving task updates out of update_job_common, and handle them differently in bulk_update_job.
  Bug #15867: Updated some code to make poms installable via setup.py; which  included a local poms
  Feature #15947: In main menu, get the composition/edit links under a different heading from info links


v2_0_0

New Features


  Feature #14270: Allow users to run arbitrary executables/scripts and workloads through the system via arbitrary launch scripts/executables
  Feature #14271: Support the model of sending data to jobs
  Feature #14272: Supports data externally pre-staged manually at sites (i.e. different site local caches)
  Feature #14274: Have appropriate permissions and privileges implemented to authorize each operation


Improvements

  Feature #14248: Now we are using Elasticsearch to fetch job data.
  Feature #15044: Allow editing of param_overrides on campaign recoveries through UI


Bugs Fixed

  Bug #15007: If we get a repeated error (all retries fail) on a SAM, POMS Stop querying.
  Bug #15349: The job_log scraper had its reporting threads crashing and stopped actually reporting things.
  Bug #15332: Some jobs have two job_histories records for one job.
  Bug #15501: Campaign page breaks if accessed w/o authentication.
  Bug #15499: In output_pending_jobs POMS only lists files that match the output format for the job type. Furthermore, update_job only flags files as output files (and not log files, etc.) if they match the output format
  Bug #15447: Database deadlock error


v1_0_1

New Features


  Update fife_launch in fife_utils to integrate poms_client calls #14471:


Bugs Fixed


  Statistics pages use campaign history to pick software version avoiding change the version in the whole dataset. #12948
  The snapshot id field is filled when the task is created.  #13888
  Active for experiement showed experiments you were not in. Currently, it check if the user is actually a member. #14463
  The incorrect Job_Type and Launch Template’s names for all NOvA’s campaigns were corrected using one for NOvA #14464
  Incorrect info for Launch Host, Launch Account and launch Setup for NOvA campaigns #14465
  Change the default analysis VO in the campaign definition to production VO #14554
  Assure that when the task go to located the jobs also go to located #14476


v1_1_0

New Features


  Ability to get reports about how effective/efficient are the campaigns #13699
  Add to the Campaign (Layer) two fields: completion_type and completion_threshold. Feature #12751:
  Feature #14752: Add job log parser to get final job info
  The runtime,memory, and disk were included in the Campaign Def/Campaign info #12966
  Poms should keep a list of job launches requested while job launches are “held” #14659
  POMS hold job launches when services are “red” on dashboard. Feature #14660:
  Poms keeps a list of job launches requested while job launches are “held” Feature #14659:
  Add a script to extract VO Role=Production user info.  #14747
  POMS is integrated with SAM putting information into SAM db about campaign and task id, then  the info is fetched faster than using project descriptions Feature #14504
  New screen for a campaign “why is my job not running?”. Integrate it with fifemon #12965


Improvements


  The HTML templates were renamed to line up with the URL’s, so they are easier to find. #12933
  Improve in the labeling of the job status, now the table describe the complete jobs with the total number, number of jobs located and number of jobs non-located.. #14477
  A complete refurbish of the POMS code in order to split in modules by functionality, having independent test units. #12934
  The  Campaign Info page was updated for new fields added to Campaign(Layers), LaunchTemplates, etc. #14531
  Better split types were added allowing the user to divide the dataset for the campaign  #13707 (In testing)


Bugs Fixed

  The code for pending campaigns made a query that didn’t work if you did the whole campaign.  Furthermore, the generation of these dimension strings was factored out to common routines #13889
  When the jobs dropped out of the queue condor_q no longer suffices. Now it is stored into the elasticsearch logs.  #14376
  Task completion/launching dependencies/recoveries not happening Bug #14866
  The uwsgi threads in development do not seem to be obviously leaking memory anymore either. Bug #14886
  Now it has a sub-item for each experiment in persistent DCache, and each goes to degraded at 80% and Failed at 90%. If enough areas fill up, we hold job launches. Bug #15008


v1_0_0a

New Features


  Include pending file counts on Active Campaign summary #13734
  Including some small features requested by NOvA as: change in campaign info stat time frame, button interface to mark campaign as inactive, specify output patterns in poms. #13849
  Solved the problem that efficiency histogram convolved low-efficiency jobs with jobs with unreported data, giving the wrong metric. #14245
  Compose CampaignLayer/JobType/LaunchTemplate have now a clone button, so you can clone an existing one and fix it up. #14251


Improvements

  Update Terms Campaign-Layer/Submission/JobType versus Campaign/Task/CampaignDefinition to make it more clear for experimenters.


Bugs Fixed


  Clean up compose CampaignLayer/JobType/LaunchTemplate in order to make the interface visually better for the users. #14249
  Reporting agents retrying on 404 errors forever in development #14246
  A bug that prevent submissions go into Located status #14242
  The code that was doing condor_q was adapted to be consistent with the changes made in jobsub #14247
  The problem of incorrect dataset definition for dependent job submissions was corrected.   #14243
  Correction of the bug that was showing zero pending files for all campaigns #14250
  After the upgrade of the single sing-on the login code in fifemon status reader was no longer working #14332


v1_0_0

New Features


  Add series of recovery types to campaign definitions; and to say one campaign depends on another. #12730
  Add CampaignDependency items that attach this campaign to other campaigns, along with a file-pattern-match for what output files from the previous campaign we want (default “%” for match-any). #12892
  Self dependencies run the next batch as soon as it finish. #13278


Improvements


  Method in poms_service.py that looks for Campaigns that have had no tasks in the last week, and turns off their active flags. #12890
  Add CampaignRecovery entries attached to the CampaignDefinition, in order by “recovery_order” field, choosing recovery types from the RecoveryType table when you add entries. #12891
  After a job is marked as held then the system will kill the job. #12975


Bugs Fixed


  The job launch command timeout in order it doesn’t run forever. #12758
  The failed_jobs_by_whatever method loses tdays when you pick fields. The problem was solved.  #12931
  Some pages are missing date picker/forward-back links #12932
  Launch template edit was failing with double quotes in setup block #13590


b0_5

New Features


  Adding files-by-submission page showing requested,delivered, etc. #12193
  Each display page should handle time ranges  #11386
  Campaign should launch jobs for campaigns that depend on this one. #12721
  Services status dashboard. #12620
  File-based Task status page #12193
  task bars and job bars need jobsubjobid, not internal task/job_id. #11382
  monitor how full dcache persisitent partitions are via webpage #12727


Bugs Fixed


  joblog scraper was missing input files sometimes #12290
  Getting the correct percent efficiency for jobs
  build a status page with file-based stats as requested by OPOS
  Fix timezone shift in status pages #11379
  job reporter code did not retry properly on connection errors #12722
  Getting constraint errors when updating jobs frequently #12723
  Support older idfh better in joblog_scraper #12922


">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/release_notes/">Release Notes</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Frequently Asked Questions-----
How can I subscribe to a mailing list?


  To SUBSCRIBE to a mailing list called MYLIST:
    
      Send an e-mail message to: listserv@fnal.gov
      Leave the subject line blank
      Type “SUBSCRIBE MYLIST FIRSTNAME LASTNAME” (without the quotation marks) in the body of your message.
    
  
  
    For example:

    SUBSCRIBE poms_announce John Smith
  
  See http://listserv.fnal.gov/users.asp for further info.


Where I can find the SAM Web Client Documentation?


  
    Full documentation on the SAM Web Client may be found “here”, or by typing on a gpvm machine:

    samweb --help-commands 
cvmfs/fermilab.opensciencegrid.org/products/common/etc/setups.sh
setup sam_web_client
    
  


Where I can find the quota of my experiment?


  https://fifemon.fnal.gov/monitor/dashboard/db/fife-quotas?orgId=1

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/frequently_asked_questions/">Frequently Asked Questions</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="GUI Campaign Editor User Guide-----
  Getting there
  Sample task tutorials    
      Adding a new campaign stage in the middle
      Changing the software version in the whole campaign
    
  


Getting there

You can either:


  Edit an existing campaign
    
      Go to the Campaigns/Tagged Campaigns page from the navigation bar/menu.
      Pick the [Edit Campaign] button for one of the tagged campaigns
    
  
  Clone an existing campaign
    
      Go to the Campaigns/Tagged Campaigns page from the navigation bar/menu.
      Fill in from/to replacement strings (i.e MC9 -&gt; MC10) for one of the tagged campaigns
      Click the [Clone Campaign] button
    
  
  Clone a template/sample Campaign
    
      Go to the Template Campaigns link in the navigation bar/menu (NOTE: not yet implemented)
      fill in a replacement string for the “generic” in the campaign
      Click the [Clone Campaign] button
    
  


You should now be at a screen that looks like:



You have


  a “Default Values” box with values common accross your Campaign Stages.
    
      you can click the [icon] box to see the form to edit the values,
      and then click the [icon] box to hide the form again
    
  
  a diagram of the campaign stages with dependencies connecting them.
    
      each campaign stage has an [grid icon] you click to toggle the view of the propreties edit form
      each dependency link has an [grid icon] you click toggle the view of its properties edit form
    
  
  Above the diagram are buttons to
    
      create a new stage in the campaign
      link two stages with a dependency
    
  
  Notes on stages
    
      stages are draggable so you can make room for new stages.
      the edit form also has an [recyle icon] you click to delete that item
    
  
  There are also boxes for the campaign’s
    
      job type(s) and
      login/launch templates
    
  


Sample task tutorials

Adding a new campaign stage in the middle


  Go into the editor
  drag the campaign stages following where you want to add it over to make room
  remove the existing dependency
    
      click the [grid icon] on the dependency line
      click the [recylce icon] on that form
      confirm the popup
    
  
  click “New Stage”
  Enter its name into the popup
  Click the previous stage to highlight it
  Click the new stage to highlight it
  Click on “Add dependency”
  Click the previous stage again to un-highlight it
  Click the following stage to highlight it
  Click the “Add dependency”
  Click Save


Changing the software version in the whole campaign


  Go into the editor
  click on the Default Values [grid icon]
  change the software version
  click the [grid icon] again to close the form
  Click Save
  you can click the individual stage [grid icon] to open/close the form to make sure they havent overridden it

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/gui_workflow_editor_user_guide/">GUI Campaign Editor User Guide</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="User Documentation-----
  POMS Overview    
      Basic Concepts
      Getting access: New Experiments, New Accounts, Users and Roles
      A  “Practical Scenario”
      The “Big Picture”
      Drilling down
      Compose a login/setup script
      Compose a job type
      Compose a campaign stage
      Bringing it all together
      Running the Campaign.
    
  
  POMS: Navigation Overview
  POMS: Detailing the components
  Campaigns
  Campaigns Actions    
      Add a campaign
      Clone an existing campaign
      Launch the campaign
    
  
  Campaign Stages    
      Editing a Campaign Stage
      Campaign Stage Login/Setup and Job Type
      Campaign Stage Datasets and Split types
      Campaign Stage Page Information
      Cloning a Stage
    
  
  Sample Campaigns
  Monitoring
  Campaign Editor
  Glossary


POMS Overview

The Production Operations Management System (POMS) is a project designed to provide  a service to assist production teams and analysis groups of experiments in their MC production and DATA processing. As the quantity of data originated by the running experiments greatly increases, the ability of simplifying the steps in data processing and management has become more and more appealing to the users.

POMS provides a web service interface that enables automated jobs submission on distributed resources according to customers’ requests and subsequent monitoring and recovery of failed submissions, debugging and record keeping.

POMS is interfaced to the following systems:


  
    Jobsub: a service that provides support for the job lifecycle enabling the management of jobs on distributed resources, such as the Grid.
  
  
    SAM: the data handling system, to keep track of files, their meta-data and processing.
  
  
    FIFEmon: for monitoring.
  
  
    FIFE_UTILS
  
  
    ECL, the Electronic Collaboration Logbook  where experiments can keep track of the production and processing operations as a collection of records chronologically organized in the form of “logbook entries”.
  


The ultimate goal is the most efficient utilization of all computing resources available to experiments, while providing a simple and transparent interface between users and the complexity of the grid.

POMS runs behind a web service interface that provides both interactive pages to the users, and a REST interfaces to scripts that interact with it. This means that experiments can use POMS through their web browser to configure and run their production code, or they can use the poms_client and poms_jobsub_wrapper tools to submit jobs through a command line and have POMS tracking, debugging and monitoring them.

To help understanding some terminology used in this document a Glossary  is provided.

Basic Concepts

POMS employs the concept of a “Campaign” to achieve the goal of data processing.  A “Campaign” is a collection of one or more stages executed in a user defined order to achieve the goal of data processing.

Each campaign stage configuration involves three main steps, mainly the definition of parameters  and actions which will be used to launch the jobs:


  
    Compose a login/setup.
  
  
    Compose the job type.
  
  
    Compose one or more campaign stages providing the login/setup template and job  types previously defined.
  


Note: Both the Login/Setup and Job Type definitions can and should be reused.

Getting access: New Experiments, New Accounts, Users and Roles

To be able to use POMS interface the user needs to have an account. As this account has a level of authority in the experiment, its creation must be approved by the experiment.  The user needs to do the following to request an account (We assume the user has already a Fermilab Service account).

  Open the webpage to Service Now(SNOW) and login using the Service account.
  Select the tile “Request Something”.
  Select the tile “Experiment/Project/Collaboration Computing Account”.
  Choose your experiment.
  Choose the role “Production” or “Analysis”.   Analysis can view production campaign data, but cannot yet create its own.


It can take up to one hour from when your request is approved until it appears in POMS.

When a new experiment is interested in using POMS, a Service Desk ticket needs to be opened with the request. The user can go the Service Desk Website
Scientific Computing Services , select Scientific Production Processing and under the ‘Get Help’ select ‘Submit a request to service providers’.

POMS has a concept of user Roles to control various operations on the components. User get assigned role also outside POMS through FERRY. Depending on the role, a user can perform certain actions.

Three roles are provided : superuser, production and analysis.


  The highest role is  superuser . This used to be coordinator  but has been changed to superuser to comply  with FERRY. To acquire the super user role go to the SNOW page “Add/Remove JobSub Group Superuser of an Experiment. When you click on the link you will have to follow and submit a form with your information. A user with this role can modify any jobs.
  Those with production role are able to modify ALL production templates.
  Those with analysis role can only modify their templates.


When logging in POMS, for the first time, the user has, by default, the lowest role allowed for the account/experiment.

A  “Practical Scenario”

Let’s envision a very possible scenario for an experiment during the initial phase of simulation:

We want to use the production processing to simulate and recostruct events in a portion of the detector to test reconstruction accuracy.   Most likely we would use a MonteCarlo type programs to generate particles events in a detector, store data in files  which in turn will be used to reconstruct the events and then finally analyze the data.

From POMS point of view, the overall process will represent a ‘campaign’ with possibly five stages:

Stage 1: Event Generation jobs.
Stage 2: Geant simulation jobs.
Stage 3: Detector Simulation jobs.
Stage 4: Reconstrution jobs.
Stage 5: Analyzing jobs.

Basic information need to be provided for each stage to achieve the goals of the whole campaign which could be simplified as the “who-where-how”:

  who
    
      the account to use to login into the host (unix account)
    
  
  where
    
      the host on which the login script will be launched
    
  
  how
    
      the script to use to configure the environment
      the job types to be used for each stage
      the scripts to be used when submitting the jobs and the parameters to be used
      the dependency between stages
      the criterion to determine when a stage is considered finished so we can move on to the next stage
    
  


Those steps are specified and grouped in three type of templates: “Login Template”, “Job Types”, “Campaign stages” which will be first viewed in the next section before expounding  in the details .

The “Big Picture”

Before entering into the details of the components, let’s examine the following “Big Picture” for a hypothetical campaign called eve_mc which could represent the above ‘Practical Scenario’.
This representation is done using the Campaign Editor, a POMS built-in tool which allows to create and manipulate campaigns. Details on how to use the tool  are available in the Campaign Editor User Guide User Guide.



Let’s see first a brief description of the elements in the campaign’s layout:


  Login/Setup : This is the basic component which defines the host from which jobs will be launched, the account used to login into the host and the environment POMS configures for the jobs that will be launched. If you double click on the ‘generic_fife_launch’ login/setup element you will see the following:





  Job Type : This defines the type of job used for processing. Strictly speaking, there is no ‘field’ to store the job type, instead,  the type is the result of the launch script and parameters which are used to accomplish the purpose of the job.  As a suggestion, the user could give  it a meaningful name to reflect its purpose, for example ‘Myjob_MC’ for a MonteCarlo job.
If you double click on the ‘generic_fife_process’ login/setup element you will see the following:





  Campaign Stage: A stage consists of a Login/Setup, a Job Type and a set of definitions and parameters used to run the jobs for accomplishing a ‘stage’ of the whole campaign. Campaign stages can be connected by dependencies, for examples, files produced by one stage can be used as input for the next stage.
If you double click on a stage element you will see the following:





  Campaign Stage Dependency: It defines how the stages depend on each other, typically specifying the file pattern of the files produce by one stage and used as input by the next stage.
If you double click on the arrow between two stages you will see the following:





  Campaign Defaults:  default values used when adding a new stage. If you double click on the arrow between two stages you will see the following:




Campaign stages can branch out, have further dependency and eventually come back together. An example of a possible scenario based on the previous example could be if after generating the events, the user wants to continue the simulation under two different detectors configurations, with and without noise , and then compare the results.
The picture below shows this new scenario:



Now let’s see the components in more details. The basic components can be created following the links in the Main Menu; Sample Campaigns are also available to provide samples of campaigns which can be cloned and then customized using the Campaign Editor.

Drilling down

Campaign definition, as already mentioned,  involves the definition of a login/setup , a job type  and one or more stages.
We strongly reccomend to use the Campaign Editor to define the  campaign stages, however, they can all be built using the links from the main menu.
At the time of writing, creating a new login setup and a job type can ONLY be done using the links from the main menu and that is shown in the following sections.

Compose a login/setup script

Campaign setup involves the definition of a login/setup which is a collection of bash commands to be executed on the experiment’s user defined host to establish the environment from which POMS will launch all jobsub jobs.

As a user may belong to more than one experiment, as a first step, make sure you select the experiment and role from the pull-down menu on the top right corner.

Templates can be reused, cloned  and modified for different campaigns and are available to other users as well. So you can use the same template for different processing campaigns.

Existing templates could be viewed following the  ‘Compose Login/setup’  link on the main page side panel to see if there is already a template usable for the purpose.  To create a new template just click the ‘Add’ button at the bottom of the page.



Four fields need to be added or modified depending on the action:


  
    Name: Define the name of your login template. When you clone the login setup, the name will show with the prefix ‘CLONE OF:current name’
  
  
    Host: Define the interactive node or machine you are going to use to launch the login/setup script.
  
  
    Account: Define the user login account for the launch (ex.  novapro, minervapro, minervacal, uboonepro, etc )
  
  
    Setup: Define the environment variable, setups, or scripts that you usually setup on your own machine (e.g. setup_nova, launch script)  if you were to launch the jobs from the shell command line.
**This must be done in one semicolon separated shell line, one line only, no  otherwise the script will break.**  
Typically, as part of the setup, [FIFE_UTILS](https://cdcvs.fnal.gov/redmine/projects/fife_utils/wiki) and [JOBSUB](https://cdcvs.fnal.gov/redmine/projects/jobsub/wiki#Jobsub-services-on-fifebatch-infrastructure) are used.
  


Note: The Account above will need the following .k5login entries:

   poms/cd/fermicloud045.fnal.gov@FNAL.GOV
   poms/cd/pomsgpvm01.fnal.gov@FNAL.GOV
   &lt;YOUR KERBEROS USERNAME&gt;@FNAL.GOV


You MUST add your default principal to the .k5login file if the .k5login file exists.  So if you’re creating a .k5login file for the first time don’t forget to add your account name in addition to the poms ids.  Your Fermilab username must be lower case and the FNAL.GOV must be uppercase.

Compose a job type

Next step is to compose the job type. A Job ‘Type’ is a way of categorizing the job based on its purpose, for example, Monte Carlo, Calibration, Reconstruction etc. Jobs of the same ‘type’ will typically have same or similar set of parameters.
Since the Job Type defines the purpose of the processing accomplished in a certain stage, you can have different job types for the different campaign stages.
Furthermore, a typical way stages are connected is through the use of files produced by the previous stage and before the next stage can be started, you need a way to let the work flow know that the previous stage is finished.  This is also done configuring the Job Type.

You can view, create or clone existing job types following the main menu link to ‘Compose Job Type’.

The page might show existing job types; as per the template you can modify existing ones or click the ‘Add’ button to create a new one.



The following are the fields that need to be filled:


  
    Name: A name that describes the kind of job campaign you are running (eg. Nova raw2root keepup FD, rock_neutrinoMC, minerva_cal).
  
  
    Output file patterns: The output pattern you are interested in your campaign (eg. %.root)
  
  
    Launch Script: In this field, you need to put the script that you run to submit jobs in your machine. In the example above, we specify the config file where variable definitions are specified to be used by fife_launch. Example of a config file can be found clicking on the ‘Config File Templates’ link from the main menu.
  
  
    Definition Parameters: The arguments your launch script (included in Launch script) used for the submission. In the example above, we specify to submit 5 jobs.
  
  
    Recovery Launches: When jobs complete there might be errors so that you want to re-launch the campaign stage: a Recovery Launch field is where you specify options to re-submit jobs based on their failure.  Example of available options:
    
      added_files: include files added to definition since previous job ran.
      consumed_status: include files which were not flagged “consumed” by the original job. In the example above, we specify to re-submit starting 3 jobs.
      delivered_not_consumed: include only delivered files which were not “consumed” by the original job.
      pending_files: include files which do not have suitable children declared for this version of software.
      process_status: like consumed status, but also include files which were processed by jobs that say they failed.
    
  


About the use of the ‘Output file patterns’:
User’s Jobs can use input files and produce output files  (it is responsability of the user’s job to declare the files to SAM for further data handling).
From the POMS perspective, when configuring the JOB type, the user can specify the output file patterns of the files produced by the jobs; these will be then used by POMS to check on the ‘completion’ level of the campaign stage the jobs ran for.

About the use of the ‘Launch Script’: 
The launch script is used when starting the job using, in typical case fife_launch (example [mvi: change accordingly when showing the real example..]):

  fife_launch -c /sbnd/app/users/dbrailsf/poms/soft/srcs/sbndutil/cfg/poms/sbnd_launch.cfg


POMS strongly suggests the use of fife_launch which is a config-file based job launcher script; fife_launch is the front-end to jobsub_submit which is part of the Jobsub client library which in turn does the final job submission.
Example of a config file can be found clicking on the ‘Config File Templates’ link from the main menu.

Compose a campaign stage

A stage belongs to a campaign so the only way to create a stage, since POMS version &gt; 4.X.X,  is to use the Campaign Editor.
In previous versions a form was provided when selecting  the ‘Compose Campaign Stages’ menu item under ‘Configure Work’ but this has been discontinued.
For a detailed description of the fields and how to create,edit etc a stage please refer to the Campaign Stages section.

Bringing it all together

Using the Compose Campaign Stage from the main menu implies filling up the forms for each stage to build the whole campaign. 
This is where the Campaign Editor becomes very useful so you can create all the stages and define how the stages depend on each other.
Let’s see how we can get to the campaign eve_mc used in the initial example using the Campaign Editor.
Let’s assume we have already defined the Login/setup and the job type. Also, let’s assume we have created one stage for it, so basically starting with the following picture:



As you can see in picture below, if you right click on the existing stage a pop up window will show up where you can ‘Add Node’ which is the editor generic notation for ‘Add stage’ in our case; replace ‘ undefined’ with the stage name you want, in our case eve_g4: click OK and you will end up with what it is shown in the picture on the right.

  

The second stage has been created with the default values and you can then open the form and change the fields accordingly.
The arrow that connects the two stages represents the dependency from the first stage. Double clicking on the arrow it shows the type of dependency, in this case stage eve_g4 will use files with pattern ‘root’ created by eve_gen.
If we  continue to add stages in the same fashion  the whole campaign will be generated.



Running the Campaign.

Now that the campaign has been defined, we can launch jobs, and to do so,  under the main menu, section  ‘Campaign Data’ click on  Campaign. This will show all the existing campaigns.  
You can filter on the names to find your campaign and then click on the ‘Launch’ symbol to start it;  this will start it from the first stage.

Find more information in the Campaigns section below.

POMS: Navigation Overview

Lets see a general description of POMS from the Navigation perspective.
Logging into POMS will direct you to the Home Page:



On the top right corner two selector fields show the experiment and the role based on your account; if you belong to multiple experiments you will be able to select accordingly.

The Main Menu on the left panel is organized in various sections which allow the user to view, configure and monitor the work:


  External Links:
    
      Logbook: Link to the Electronic Collaboration Logbook for the experiment if available.
      POMS SNOW Page: Link to POMS Service Desk Page (Service information)
      Downtime Calendar: Link to the Scientific Services Outage Calendar
    
  
  Experiment:
This page shows the members of the current group/experiment. Data is presented as a table which lets you sort and filter the results to easily find people:
    
      You can click on column headings to sort the data.
      You can type substrings in the boxes under the column headings to filter for matches.
    
  
  Campaign Data:
    
      Campaigns: link to the list of existing campaigns for the experiment.
      Campaign Stages: link to the list of existing stages.
      Sample Campaigns: link to the list of existing samples to be used as templates when creating new campaign.
    
  
  Configure works:
    
      Compose Login/setup: link to the list of existing login templates and possible actions.
      Compose Job Type: link to the list of existing job types  and possible actions.
      Compose Campaign Stages: link to the list of existing stages  and possible actions.
      Config File Templates: link to some useful templates that can be used when launching jobs.
    
  
  Jobs:
These links direct to Landscape plots to monitor campaigns and jobs status.


From the center tiles selection

POMS: Detailing the components

Campaigns

One of the most useful section from the Menu is the ‘Campaign Data’. Under ‘Campaigns’  you can view  all the campaigns and select various actions on them.
In the following pictures, a filter on the campaign name has been applied to narrow down the list.



Results can be sorted  by clicking on column headings and can be  filtered by typing strings to match in the boxes under the column headings.
You can configure what is displayed on the page from the group of check boxes. By default, you will see Active campaigns that belong to you and others  with Production role.


  You can perform some actions on the campaigns using the green buttons:
    
      Using the ‘Select’ check box you can pick which campaign(s) to modify to change  the active/inactive status or assign (or remove) a tag.
      Click on ‘Add’ button to add a new campaign.
      Click on ‘Pick .ini file’  to select an existing ini file and then Upload it and in so doing create a new campaign based on the information in the ini file.
    
  
  Clicking on the campaign name you will be redirected to the campaign stages page.
  Clicking on ‘Submissions running’ shows how many submissions are current.
  Clicking on ‘Submission History’ you will see the submissions for the current week and you can navigate back and forth in time.
  Clicking on ‘Dependencies’ it shows all the stages for the campaign.
  Clicking on ‘GUI Editor’ you will be redirected to the Editor page where you can update all the components of the campaign.
  Clicking on  .ini File you will be presented with a page with the list of all the campaign components and dependencies; this file can be saved and modified for further use. For example, it can be updated and then uploaded back into POMS using poms_client API.
  Tags would show tags assigned for the campaign. People use tags to group campaigns by ‘theme’. Tags can be useful when filtering to narrow down the list.
  You can ‘Rename’ and ‘Delete’ a campaign.


Of the several actions that can be performed on the campaigns the following:

  Add a campaign
  Cloning the campaign
  GUI editor


Will direct you to the use of the Campaign Editor.

Campaigns Actions

This section looks a little more in details on the actions you can perform from the Campaigns page.


  Add a campaign.
  Clone an existing campaign.
  Launch the campaign.
  Pause the campaign.
  Resume the campaign.
  View results.
  Re-launch and kill it.


Add a campaign

When you choose Add a campaign, after being prompted for a name, in this case eve_calib was given, you will be presented with the following page:



A basic campaign skeleton is pre-built with default values, one generic stage which uses the generic login setup and job type.  This example will be used in the Campaign Editor documentation to show how to use the tool.

Clone an existing campaign

For this purpose we will go to the Campaigns page and clone the Campaign eve_demo which has 3 stages and  different job types for each stage.
You will be prompted for a new name, in our case eve_test, then you will be redirected to the Campaign Editor Page.

The following picture illustrates the original campaign and the cloned one as they appear in the campaign editor.



As you can see, the new campaign has the new name assigned but all the stages have the same names as the original, HOWEVER once saved, they become private to the new campaign.
In the bottom section the Login setup and job types are NOT cloned. This is purposely done since multiple campaigns could use same job types and users are encouraged to re-use them. 
However, if you need to change some field in the job type, then you must give a new name so that another job type will be created for your campaign so that nothing gets overridden in the original.
For a visual quick association, each stage color is the same as the associated job type.

The following picture shows how to change the name of the cloned stage to be more appropriate to the campaign:


The following picture shows the final campaign after changing the stage names.



Launch the campaign

Now that the campaign has been created, you can launch it going to the ‘Campaigns’ page , find the campaign and click on the ‘Launch’ button.

This will launch the first stage,  eve_test_gen_v1.

The ‘Submissions running’ will show that the campaign has submission. Then you can check also on the ‘Submissions History’ page:



As previously stated, each stage has its own page and can be individually launched which can be good in case of failure;  However, since the stages depend on each other, if no problems occur, after launching from first stage the whole campaign will be executed.

On the previous picture you can see that ‘Commands’ can be execute on the stage:

  Pause
  Resume
  Cancel


At this level, the commands will be executed on the jobs running at the Condor level.  If you choose to ‘Pause’ the jobs, keep in mind that at Resume , jobs will be re-submitted.
Just an example of possible use of the ‘Pause’ at this level could be to free resources to launch another campaign that has become higher in priority for your accomplishments.

You can see in the following picture that the first stage has completed and the second stage started (top part of the picture) and then you can see that all three stages have completed.



From the following picture you can see that the ‘gen’ stage is finished and the stage ‘sim’ is in ‘idle’  which could mean that part of the jobs are waiting in the queue to run.
You can click on the Status History green button and see the various states and the transition time.



To get more information on the submitted jobs for the stage, you can follow two paths:


  Go back to the Campaign page, click on the campaign to find all the stages and then click on the stage, in our case eve_test_gen_v1 .
  Go to the ‘Campaign Stages’ page, find the stage and click on it.


Either way you will end up on the Campaign Stage page from which you can view all the information about the stage and the jobs:



A lot of information is available for the stage and we will cover the details under the Campaign Stages section.

However, worth of mentioning here, is the action ‘Queue future job launches’. 
When we launched the campaign, as mentioned, if all goes well, all the dependent stages will start in cascade based on the dependencies.

This action allows you to override  the automatic flow. A useful scenario where the user might want to use this,  could be the following:


  Our campaign has three stages; stage 1 produces output file that would be the input for stage 2. Let’s say we want to check that the files have the correct format first before automatically continuing to stage2: this is where we would queue jobs for future launches for stage 2. When we are satisfied with our checks we can resume and the campaign will continue till completion of stage 3.


To monitor the jobs, you can go to the ‘All Jobs’ in Landscape and see the list of jobs running. The following  pictures illustrate  fifebatch monitoring page where you can see  jobs for the first two stages,  gen_v1 and sim_v1.



If a stage had some issues, for example not all jobs succeed, the batch job Status would appear as in the following pictures where we use a different campaign to show what to expect:





Campaign Stages

Campaigns can have one or more stages. Stages represent different workflows for the campaign depending whether they are dependent on each other.
To view all the stages you can select the ‘Campaign Stages’ option from the side panel or you can go to the Campaigns page and click on the campaign of interest and you will be redirected to the stages page.



The table shows campaigns and the associated stages. You can sort and filter to narrow down the choices. Clicking on a stage you will be redirected to the stage page where you can view all the stage information.
This will be covered later on under the  Campaign Stage Page Information section.

Editing a Campaign Stage

Because the stage belongs to a campaign, to add or modify stages you will use the Campaign Editor.
As an example, here we will keep using our eve_test campaign. From the picture you will notice the color coordination between each stage and the job type, just an easy visual way to associate the items.



The following picture shows how to view and edit the stage. As a side note, you might notice that the eve_test_gen_v1 stage position on the editor board has changed to better view the layout.
Moving the elements around can be very useful when campaigns have many stages; the new position is saved as well when you save the campaign.



Let’s examine in details the fields for a stage: some are text fields, some are pull-down menus and some upon ‘Edit’ will open other pop-up windows:




  
    Name : the name for this stage, which,  as a suggestion, it could be something meaningful for the purpose of the stage.
  
  
    VO Role: the role to use for jobsub when submitting jobs for this campaign. It can be “Production”, “Analysis” or in some cases “Calibration” or others provided they exist in the experiment VO role.
  
  
    Experiment Software Version: the software version. Typically experiment software components are bundled up in a version to be used by the running jobs.
The version will be set in the metadata of output files generated by this campaign.
POMS assumes files have metadata that lists their parentage, and software application information; it can then use the software version, filename patterns, and parentage to define datasets for the output of this campaign layer.
Please be advise for the following: To propagate this value to the launch of the jobs, the user need to either:

    
      
        specify %(version)s  in the launch/setup command, example:

        source myexp.sh; setup myexpcode %(version)s; OR
        
      
      
        specify it as override parameter when using fife_launch, example:

        fife_launch -c my.cfg -O global.version=$(version)s;
        
      
    
  


If you don’t use either cases, the software version will be stored in the database as information for the stage BUT NOT used.


  
    Dataset or split data: Dataset this campaign stage will process. If this campaign is only ever run as a later stage in a workflow, this is ignored. This field is used in conjunction of the split type when appropriate.
  
  
    Dataset Split Type:  It specifies how the Dataset could be split, please refer to Dataset and Split Types below for details.
  
  Completion Type:  This is where you specify the criterion  used to be able to move to next stage. Two options are available:
    
      Complete:  to say the campaign layer submissions are complete when their jobs complete, or
      Located:  to say the layer is completed when the submissions output files are located.
    
  
  Completion %:  This is related to the completion type: please advise that the percentage refers to the jobs in both cases:
    
      If you say that Completion type is ‘complete’ and specify a completion percent of 75%, then the campaign will move on to the next stage when 75% of the jobs are completed.
      If you say that Completion type is ‘located’ and specify completion percent of 75%, then the campaign will move on to the next stage when 75% of the jobs are completed AND 75% of  the output files are found in SAM.
    
  
  Parameter Overrides:  This allows you to override parameters to your Job Type’s launch command.  Clicking on the edit icon will pop up a window where you can specify the parameter as a key-value pairs that will be concatenated and put on the command line.
    
      Note that matching keys will replace matching keys from similar parameter lists you had previously assigned in the  Definition Parameters in the Job Type.
      Note that the values in the Parameter Overrides will have Variable Substitution performed on them.
    
  
  
    Test Parameter Overrides:  These are used in the same fashion as the Parameter Overrides but only when Testing the campaign submission (see later).
  
  
    Depends On: This lets you define the dependencies on other campaign layers that this one has. Note that to add a circular dependency (i.e. to make this campaign auto-launch the next submission as each one completes) you have to have saved the campaign at least once, so it will show up in the list of campaigns to choose from.

    
      For example, if you had a campaign stage “stage1” that provides output for “stage2”.
      
        You would want to define the previous stage, and the output file patterns to use on stage2 as:

        {&quot;campaign_stages&quot;: [&quot;stage1&quot;], &quot;file_patterns&quot;: [&quot;%%&quot;]} 
        
      
    
  
  Login setup: The login setup script to be used: a collection of bash commands to be executed on the experiment’s user defined host to establish the environment from which POMS will launch all jobsub jobs.
  Job Type: A Job ‘Type’ is a way of categorizing the job based on its purpose.


About Parameter Overrides: the following example shows how to override a parameter defined in the config file using the value of another existing parameter also defined in the config file:

Let’s say we have the following in a config file:

[global]
...
outdir=/pnfs/exp/scratch/exppro/poms/jobs/outputs
...

[job_test_output]

job_outdir=/pnfs/scratch/exppro/


For a certain stage in our campaign then we want to override the job_outdir with the value of outdir.
Then using the editor for the param override field, for the key-value pair we would specify the following:

key                                 value

-Ojob_test_output.job_outdir         &#39;%%(global.outdir)s&#39;


so then when  you launch, in the command line it will look like:

-Ojob_test_output.job_outdir=&#39;%(global.outdir)s&#39;


The single-percent is for a POMS defined value, and the double-percent one is for a value in your config.

Campaign Stage Login/Setup and Job Type

The following picture shows the Login/Setups and the Jobtype for the current stage.


For details on the Login/Setup and Job Type definition please refer to Compose a login setup and Compose a job type sections.
One thing to keep in mind is that the Login/Setup and the Job Type are now campaign specific, they may be shared by other campaigns; if this is the case and you want to change any of the fields in either components you will be asked to change the name not to affect other campaigns.

Campaign Stage Datasets and Split types

The following picture shows the available Split types.



Depending on the selection, more information can be filled in the form accordingly and also in the dataset or split type data field for which  an ‘Edit’ button may appear.
For example, if you choose a split type of ‘list’ then you will use the dataset field to specify the list itself, see example below:



In this case three datasets have been assigned, ds1,ds2 and ds3 leading to use ds1 in first submission, ds2 in second etc etc.

Another interesting example for  split types is the ‘multiparam’ option:



When you select the multiparam split type and accept it, the field ‘dataset or split type data’ on the form appears with an additional ‘Edit’ button to pass the desired information.
The final results is a list of lists: internally this is translated  in all the possible permutations which will be used, one per submission.
Example, let’s say you want to generate different particles at different energies to produce data to be used in particle simulation through a detector.
So you could enter the following data:



This will generate the following permutations:

  electron_1GeV
  muon_1GeV
  electron_3GeV
  muon_3GeV


and if you submit the campaign, you could see in the log for the eve_test_gen_v1 stage, for example,  the following

....
fife_launch -c cfg/generic.cfg --stage=gen  -Oglobal.    sam_dataset=electron_1GeV -Oglobal.release=v1_1 -Osubmit.N=5
....


and if you submit again:

....
fife_launch -c cfg/generic.cfg --stage=gen  -Oglobal.    sam_dataset=muon_3GeV -Oglobal.release=v1_1 -Osubmit.N=5
....


If you try to submit more times than the number of permutations, in our case 4, you would get and error and to submit again,
from the stage page, you need to reset the ‘Last Split’, see the following snippet from the campaign stage page:



Campaign Stage Page Information

Each stage of a campaign has its own page with a lot of information:



The page has several sections organized by the type of information they present:

The top section shows plot generated within Landscape with statistics for the last 30 days.


  Job status for the campaign stage
  Reports
  Actions
  Campaign Stage general information
  Job Type information
  Login/Setup Information
  Diagram with stages  immediate dependencies.
  Links to Recent Launch Outputs.


Reports:
Two types of reports are available (for a more general description with pictures see the Monitoring section below:


  Reports generated and available from the Landscape web pages
    
      Production Shifter Page:  a summary for the last 24 hours for your experiment of all the campaign/stages jobs.
      POMS Campaign Stage: a summary for the last 30 days for the jobs for the selected stage.
      Campaign Stage Stats: a summary for the last 30 days with efficiency ,memory requests and usage.
      Submissions: a summary for the lat 7 days on the submission with details on the jobs.
    
  
  Reports generated within POMS.
    
      Campaign Stage Submissions: by default it shows information for the last 7 days but you can navigate in the paste and future. You will see, for example, all the submissions history, current status and commands you could issue.
      Campaign Stage Submission Files: a summary for the last 7 days on all the files for the jobs with SAM related information.
    
  


Actions:


  Editing: this will redirect (for now) to the stage form not the editor, which we strongly suggest to use to update the stage.
  Launching the campaign: before starting it, you can view the commands that will be executed clicking on commands (see more information about this below):
    
      If you are sure to start the campaign for production , you would  click on ‘Launch Campaign Jobs Now’,
      If you prefer testing first  you can select the ‘Launch Campaign Test Jobs Now’.
In either case, after confirming the launch, you will be redirected to the log page. 
The user can verify the status of the jobs choosing various options in the ‘Reports/Status’ section.
    
  
  Kill, Hold, Release jobs: these actions are to control the jobs on Condor.
  Schedule Future Job Launches: this is to setup a crontab job or use an existing one.
This page lets you generate/update a crontab entry to push the “launch jobs” button for this project on a schedule.
If there is a current crontab entry , it shows in the labelled box, otherwise it shows “None”. To set times, fill in the lower form with cron values (see the cron man page for more information).
For example, to run it at 3:00 every morning, you would fill in 0 in Minutes, 0 in hours, and check All for the days of the week, and leave days of the month as an asterisk “*”.
Or to run it on the first of every month, set fill in as above, but set the days of the month to “1”. Then hit “Submit”, and the current crontab entry should update, and you have scheduled an entry.
To stop submissions, the “Delete” button should clear the current entry to “None”.
  
    Queue future jobs launches: This action allows you to override  the automatic flow for a campaign where stages depend on each other and the next stage would automatically start when previous has finished. A useful scenario where the user might want to use this  could be checking that output files from the current stage are correct before feeding them as input to the next stage.
  
  About showing the commands to launch: when you click on this, a page with the list of commands to be executed will appear: Please notice though , that a submission id is reserved at this point in case you do decide to execute the commands and launch it.
If after commands  you click on  ‘Campaign Stage Submission’ on the stage page, you will see the submission id for the stage and the status is New.
If you decide NOT to submit using the commands, after two hours the launch will be automatically killed for you.  See the pictures below:






Cloning a Stage

From the Campaign Editor you can clone stages; using our eve_test campaign, if you right click on, for example, eve_test_gen_v1 stage, the ‘Add Stage’ pop up window will appear.
An interesting way to clone, is simply to specify how many ‘copies’ of the original you want, 3 in the example, using the simple syntax  *3 :



and you will end up with three copies with a default naming conventions as shown in the next picture:



The new stages are created independently from each other and they all inherit the fields and definitions of the original stage.
At this point you can edit them and do whatever you need. Remember to save them!

Sample Campaigns

POMS provides few sample campaigns for the user to view and clone; then the cloned campaign can be saved and modified accordingly using the Campaign Editor.
Few sample campaign are provided which you can view to see which one could fit your purpose.



When you click on ‘Clone Campaign’ a pop up box opens up in which you specify the desired name for the cloned campaign.
You will notice that the name you provided, in this case mvi_test, replaces the word ‘sample’ in the original campaign name.



Another thing to notice is that the stages have kept the original names: since stages belong to a campaign, duplicate names across campaigns are allowed.
Remember to save the campaign before leaving the Campaign Editor.

Monitoring

After launching a campaign you can monitor the jobs either viewing Kibana plots in Landscape or check the status within POMS.
Let’s use for our examples the campaign f_demo_2_mvi which has three stages:

  f_eg_v1
  f_sim_v1
  f_reco_v1


Launching the campaign it will launch the three stages in sequence, provided all goes well. To monitor we need to go the the first stage page (we will show just the top section of the page):



If you follow the link for Campaign Stage Submissions you can see the leader job in a ‘New’ state:



After a little bit, if you view the same page again, you can see that the stage is in running mode and you can click on History to see the transitions:



You can see jobs information also viewing Kibana plots in Landscape selecting the ‘All jobs’ option from the ‘Jobs’ menu item on the side panel:
In the following picture you can see jobs for all the three stages



Then, checking the Campaign stage submissions again, you can finally see that all three stages have finished and you can view the individual history with the transitions times:




  
    Campaign Editor
  
  
    Glossary
  

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/user_documentation/">User Documentation</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Launch Config File Templates-----Here we provide sample config file templates and information on what you need to fill in or adjust for your individual needs.

This requires fife_utils v3_2_1b1 or later.


  Launch Config Template File
  Fife Utils Overview
  Fife Utils Reference Guide


">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/launch_config_file_templates/">Launch Config File Templates</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Campaign Layer Info-----
  Future releases

To get the full features of POMS, when creating a CampaignLayer, you should have the following information and provide it to POMS, either in the CampaignLayerDefinition or in the CampaignLayer:


  Name for the general type of CampaignLayer for the definition, and for this specific instance (i.e. MyExperimentMonteCarlo and MyExperimentMonteCarlo_v4_3_purple_events)
  Job launch details
    
      Software launch script that you use
      what VO Role to use (i.e. Analysis, Production, etc.)
      Account/host you wan the launches run from
    
  
  parameters to software launch script to set
    
      SAM dataset
      software version, that will end up in SAM metadata as application version
    
  
  Dataset(s) describing all files this CampaignLayer will process
  How you want the dataset sliced into pieces for submissions; currently supported options:
    
      new – files added since last launch
      mod_n – (where n is an integer) sliced into n chunks.
      draining – don’t slice it, the dataset is a draining dataset which already excludes already processed files
    
  
  list of types of files the CampaignLayer generates, (i.e. if your program generates a processed data file and a histogram, how do we tell them apart?)
  specify how many recoveries you want run, and what sort of recovery dataset you want to build on each recovery
  if this CampaignLayer depends on the output of another campaignLayer, which one, and what file patterns.
  if the jobs have a specific number of input/output files (i.e. it reads only one file and writes only one) what those numbers are.


Future releases

In future, we may also want to know


  memory/disk requirements
  expected job runtime


and we may have the option to increase memory usage requested for recovery jobs.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/campaign_layer_info/">Campaign Layer Info</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Schedule Launch Help-----This page lets you generate/update a crontab entry to push the “launch jobs” button for
this project on a schedule.

If there is a current crontab entry , it shows in the labelled box, otherwise it shows
“None”

To set times, fill in the lower form with cron values (see the cron man page for how to complicated things).

For example, to run it at 3:00 every morning, you would fill in 0 in Minutes, 0 in hours, and check All for the days of the week, and leave days of the month as an asterisk “*”.

Or to run it on the first of every month, set fill in as above, but set the days of the month to “1”.

Then hit “Submit”, and the current crontab entry should update, and you have scheduled an entry.

To stop submissisions, the “Delete” button should clear the current entry to “None”.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/schedule_launch_help/">Schedule Launch Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Search Tags Help-----This page is currently in development.

If you are in urgent need of help regarding this page, please contact: ltrestka@fnal.gov
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/search_tags_help/">Search Tags Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="List Generic Help-----This page is currently in development.

If you are in urgent need of help regarding this page, please contact: ltrestka@fnal.gov
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/list_generic_help/">List Generic Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Triage Job Help-----This page helps you see the information you need to decide why an individual job failed (if it did) or why it went well. You can see the job’s exit codes, log files, timeline of state changes, etc.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/triage_job_help/">Triage Job Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Fife Newsletter Article-----POMS stands for “Production Operations Management System”, and it was initially developed for the OPOS group to help them effectively manage job submissions for multiple experiments.

Now we are working to make POMS into a tool that the experiments can use directly to help track their production computing. It:


  Lets experiment production users define “Campaign layers” of specific types of work, and group them together into larger Campaigns as needed.
  Tracks job submissions of multiple jobs for those campaign layers
  Automatically performs job submissions if so configured
  Can launch “recovery” jobs for files that didn’t process properly the last time
  Can trigger launches in dependent campaign layers to process output of completed submissions
  Interfaces with the SAM data handling system to keep track of files and processing
  Provides a “Triage” interface to help debug what went wrong with failing jobs


POMS runs behind a web service interface that provides both interactive screens to users, and REST interfaces to scripts that interact with it. This means that experiments can use POMS through their web browser and configure and run their production code, or they can use the poms_client and poms_jobsub_wrapper tools to submit jobs and have POMS track them, without using the graphical interface for submission at all.

We are currently working with several FIFE experiments to start using POMS to help them manage and track their production processing, and hope to get to the rest in the next year.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/fife_newsletter_article/">Fife Newsletter Article</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Job Table Help-----
  Job columns    
      info
      jobsub job id
      node name
      cpu type
      host site
      status
      output files declared
      output file names
      user exe exit code
      input file names
    
  
  Task columns    
      input dataset
      output dataset
      status
      project
      Campaign fields
      experiment
      name
      task definition id
      vo role
      cs last split
      cs split type
      cs split dimensions
    
  

The job table is a searchable list of jobs meeting various criteria.

Job columns

info

The info column has a link to the triage page for that job, with more details,
access to log files, etc.

jobsub job id

The fifebatch job-id of the job in this row.

node name

The node if any (and if available) that this job most recently ran on. If we have not seen a report from this job about where it is running, it is “unknown”.

cpu type

Cpu type from /proc/cpuinfo logged by the job; if we haven’t received such a log message, it is “unknown”.

host site

GLIDEIN_SITE from the condor_q listing of the job.

status

Status of the job; one of the base Condor states of Idle, Held, Running, Completed, or Running: with more information from the jobs ifdh logging, or Located, which is our own state indicating it is not only completed, but all of its output files have locations in the Data Handling System.

output files declared

Flag about whether all of this jobs output files have locations in the Data handling system.

output file names

list of output file names copied out from the job, scraped from ifdh log messages that ifdh cp generates.

user exe exit code

Exit code from the user script reported by the jobsub wrapper via ifdh log.

input file names

Input files copied in as recorded by the ifdh cp log messages.

Task columns

input dataset

name if dataset input if known

output dataset

name of dataset describing output files if known

status

The task status is a rollup of the job statuses, as follows;


  if no jobs have shown up in condor_q output yet, the Task is “New”
  if all jobs are Idle, the Task status is Idle
  if any jobs are Running, the Task status is Running
  if all jobs are Completed but not all are Located, the Task is Completed
  if all jobs are Located, the task has Located status


project

Data handling system “Project” name (i.e. SAM project)

Campaign fields

experiment

Experiment whose job/task/campaign this is.

name

Name of the campaign

task definition id

Task definition of this job

vo role

Role in the vo this runs under

cs last split

Bookkeeping for splitting tasks from Campaigns

cs split type

Type of Campaign splitting done

cs split dimensions

Dimensions used to further split into multiple tasks
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/job_table_help/">Job Table Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Getting More Memory In Recovery Jobs-----
  Making jobs not go Held forever for Memory
  Adding recoevery launches

Two approaches here:


  For jobs with fixed/no inputs (i.e. event generation) use autorelease to restart jobs that get held for memory.
  For jobs which read SAM datasets, use recovery launches


Making jobs not go Held forever for Memory

Note that to make this work smoothly, you need your jobs that go over memory to not hang around in “Held” status
forever. You can avoid this by setting:

[stage_whatever]
...
submit.line_1 = +PeriodicRemove=JobStatus==5&amp;&amp;HoldReasonCode==26&amp;&amp;CurrentTime-EnteredCurrentStatus&gt;3600


in your fife_launch config, or by adding

--line &#39;+PeriodicRemove=JobStatus==5&amp;&amp;HoldReasonCode==26&amp;&amp;CurrentTime-EnteredCurrentStatus&gt;3600&#39;


to your jobsub_submit parameters otherwise.

Adding recoevery launches

You can, in your JobTypes, add recovery launches, and in particular you can add ones that override launch options to request more memory. If you are using fife_launch, this can be accomplished by


  Opening the campaign in the GUI Campaign editor





  
    double clicking on the job type

  
  change the name (maybe add _with_mem_recovery)
  click the Edit button next to Recoveries





  pick proj_status for the recovery type
  click the edit button on the right to edit the Param Overrides
  in the param editor, set the override for submit.memory for fife_launch





  Accept/OK in each popup






  check stages that use that jobtype to get the new one, and press Done





  press Save for the whole campaign.

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/getting_more_memory_in_recovery_jobs/">Getting More Memory In Recovery Jobs</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Dataset Split Types-----
  byrun
  draining
  list
  mod
  new
  nfiles
  New in v4_0_0    
      drainingn(k)
      stagedfiles(k)
    
  

POMS supports several dataset split types, and more can be added as plugins. We will attempt to document them here as they are added. They are specified with a function-like notation:

name ( parameters )

with a name and parameters as given. The following names are supported, each may have parameters as described in the following sections.

byrun

The byrun type takes parameters low and high giving a range of run numbers, as in byrun(low=3,high=12) which specifies splitting the dataset into runs starting at run number 3 and going up through run 12, inclusive.

draining

The draining split type doesn’t really do anything, and takes no parameters. It is a way to indicate the dataset definition you have given is a “draining” dataset, and should exclude any files that have already been processed, so it should just be re-used on each submission.

list

The list split type takes a comma separated list of dataset names as a parameter, and will submit with each one in turn as the dataset. The input dataset given for the overall campaign is not used to compute the splits, but should be the union of the listed data. So using list with dataset set to ds1,ds2,ds3,.. will yeild dataset “ds1” on the first submission, dataset “ds2” on the second, etc.

mod

This takes one integer parameter, i.e. mod(5) which will split the dataset into 5 chunks, taking every fifth file with a differing offset for each submission.

new

This type is supposed to take new files since the last submission, but has lots of parameters to do variations of time-window based slices of files:


  window= Lets you specify a time window to group together; that is if you want to process files a week at a time you can use window=1w.
  round= Lets you specify a timeperiod to round things to (i.e. round to nearest day).
  fts= time to assume the FTS takes to process files.
  localtime= set to 1 to use localtime rather than GMT for time windows
  firsttime=n time to start


So if you want catch up and to do one-week chunks starting at unix time 1497934800: (i.e. from “date -D 2017-06-20 +%s”)
new(firsttime=1497934800, window=1w)
it will start by picking files in the week staring at that datae, then next time the next week’s worth, etc.

nfiles

This will submit some number of files each submission using “offset” and “limit” i the dataset.

New in v4_0_0

drainingn(k)

This is a new snapshot based splitter, which yeilds up to k files not yet processed each time. Files already processed are tracked with a snapshot stored in cs_last_split, which can be cleared to “reset” the splitter and start over.

stagedfiles(k)

This is a new snapshot based splitter, which works off of a project name, not a dataset name. You can give it the project name associated with a prestage script, and it will deliver up to k files marked “consumed” by that project each time it is called.
It also keeps a snapshot of the files delivered so far in cs_last_split, which can be cleared to “reset” the splitter and start over.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/dataset_split_types/">Dataset Split Types</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Membership Help-----This page shows the members of the current group/experiment and lets you sort and filter the list to find people.

You can click on column headings to sort

You can type substrings in the boxes under the column headings to filter for matches.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/membership_help/">Membership Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Campaign Layer Edit Help-----
  Name
  Active
  VO Role
  Software Version
  Dataset
  Dataset Split Type
  Completion Type
  Completion Percent
  Parameter Overrides
  Depends On

This lets you edit particular campaigns layers.

Initially you get a list of campaigns for the current experiment to choose from, or click “[+]Add”.

Then you can pick the Name for this campaign, the VO Role, software version and dataset
for the campaign, and attach a particular Launch Template and Campaign Definition.
Also you can add ovverides/aditoins tot hte options passed to the launch script
in the Campaign Definition.

Name
A name for this campaign layer.

Active
This says whether the campaign is considered “Active”, or if it is done being run.

VO Role
The role to use for jobsub when submitting, killing, etc. jobs for this campaign.
It can be “Production”, “Analysis” or in some cases “Calibration” or something more exotic if your VO has defined such roles.

Software Version
The software version that will be set in the metadata of output files generated by this campaign.
POMS assumes files have metadata that lists their parentage, and software application information;
it can then use the software version, filename patterns, and parentage to define datasets for the output of this campaign layer.

Dataset
Dataset this campaign layer will process. If this campaign is only ever run as a later stage in a workflow, this is ignored.

Dataset Split Type
See Dataset Split Types for details.

Completion Type
You can specify either


  Completed to say the campaign layer submissions are complete when their jobs complete, or
  Located to say the layer is completed when the submissions output files are located.


Completion Percent
This lets you specify a percentage of either jobs or files to allow a workflow to proceed if not quite all the tasks hare done according to their completion type.

Parameter Overrides
This edit icon pops up a window that lets you add or override parameters to your Job Type’s launch command by specifying key, value pairs that will be concatenated and put on the command line, with a space inserted between the key and value if the “space” option is checked. Note that matching keys replace matching keys from similar parameter lists in the Job Type.

Note that the values in the Parameter Overrides will have Variable Substitution  performed on them

Depends On

This lets you define the dependencies on other campaign layers that this one has. Note that to add a circular dependency (i.e. to make this campaign auto-launch the next submission as each one completes) you have to have saved the campaign at least once, so it will show up in the list of campaigns to choose from.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/campaign_edit_help/">Campaign Layer Edit Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Raw Tables Help-----This is for use by the POMS experts, and lets you pick a table,
pick a row from the table, and edit the raw values with a form interface.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/raw_tables_help/">Raw Tables Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Held Launches Help-----This page is currently in development.

If you are in urgent need of help regarding this page, please contact: ltrestka@fnal.gov
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/held_launches_help/">Held Launches Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Experiment Edit Help-----With this page you can add experiments to POMS, and follow the link
to see who POMS thinks are admin members of the experiments.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/experiment_edit_help/">Experiment Edit Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Edit Users Help-----All new users, and all new relationships are obtained from VOMS. This page allows you look up a user/experimenter by their username. Those with the appropriate privilege can update which experiment a user is affiliated with. Relationships set to inactive will NOT be overridden by VOMS updates.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/edit_users_help/">Edit Users Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Job File Contents Help-----This page shows you file contents for files obtainable by
jobsub_fetchlog for a given file. If you want to see a different file,
you need to go back to the job triage page, and pick an other one
from the list.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/job_file_contents_help/">Job File Contents Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Campaign Sheet Help-----
  day
  date
  requested files
  delivered files
  jobs
  failed
  outfiles
  pending
  exit
  exit signal

Column definitions will be here…

day

Shows day of the week of the data in the row.

date

Shows the date of data summarized in the row. The data is a summary of that day, in UCT (Universal Coordinated aka Greenwich Mean Time).

requested files

Files requested by SAM projects associated with that campaign in that time period.

delivered files

Files delivered by SAM projects in that time period. If a SAM project was not used, then the number of input files copied in according to ifdh logging is given. This will be indicated by the requestef files being zero, but the delivered files being non-zero.

jobs

Total jobs associated with that campaign completed in that time window, or still running, in the case of the first row of the table.

failed

Number of SAM consumers which listed themselves as failed. Once again, if no SAM project is used for this campaign, this will be zero. This currently does not generate job table link, as we don’t currently have sam consumers reliably tied to jobs.

outfiles

Output files generated by the jobs, as gleaned from the ifdh logging information.

pending

Jobs which have output files which do not have SAM locations defined. Note this is the number of jobs, not the number of files.

exit

There are columns labled exit(n) for each user executable exit code returned recently. The count of jobs exiting with that exit code on that day is given; and clicking on it will take you to a job table showing those jobs with that exit code on that day. Small exit code values (i.e less than 100) are generally defined by the application running in the job.

exit signal

There are columns labled exit(n) for each user executable exit code returned recently. In particular jobs that exited due to a Linux “signal”, will have an exit code of 128+signal-number. The count of jobs exiting on that signal is given here. Exit codes and signals often seen here are:


    
        exit
        signal
        description
    
    
        130
        2
        SIGINT Interrupt signal
    
    
        132
        4
        SIGILL Illegal instruction
    
    
        134
        6
        SIGABRT Abort call (usually an assert() call in the program)
    
    
        135
        7
        SIGBUS Bus error -- usually bad pointers, etc.
    
    
        135
        8
        SIGFPE FLoating point exception -- divided by zero, etc.
    

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/campaign_sheet_help/">Campaign Sheet Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Campaign Task Files Help-----
  jobsub_job_id
  project
  date
  submitted
  delivered (SAM:logs)
  consumed
  skipped
  unk.
  w/some kids declared
  w/all kids declared
  w/kids inflight
  w/kids located¶
  pending

This is a table for the given time window (default 1 day) for the given campaign.
It shows each job submission, and counts of files handled by each. Each count
is a click through to show the list of files, and the SAM query to get the list.

The page has the following columns:

jobsub_job_id

Jobid of the submission – click through to see the time bars for the jobs, and to click through to a triage page for the jobs.

project

SAM Project name (or playlist file?) for the submission

date

date of the submission

submitted

Number of files in dataset/playlist.

delivered (SAM:logs)

Files delivered according to SAM and according to the log scraper.

consumed

Files listed as consumed in SAM

skipped

Files listed as skipped in SAM

unk.

w/some kids declared

Files we have some outputs declared for

w/all kids declared

Files we have some outputs declared for

w/kids inflight

Count of files “in flight” – that is output files we saw in the logs that are not declared in SAM yet.

w/kids located¶

Count of files with all kids declared with locations.

pending

Count of files without all kids declared with locations.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/campaign_task_files_help/">Campaign Task Files Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Launch Campaign Help-----This page is currently in development.

If you are in urgent need of help regarding this page, please contact: ltrestka@fnal.gov
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/launch_campaign_help/">Launch Campaign Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Generic Edit Help-----This page is currently in development.

If you are in urgent need of help regarding this page, please contact: ltrestka@fnal.gov
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/generic_edit_help/">Generic Edit Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Environment Setup-----
  Minimum Required Environment Variables for POMS and fife_wrap:
  Environment Variables Generated and Used by POMS    
      $POMS_DATA_DISPATCHER_TASK_ID:
      $POMS_DATA_DISPATCHER_PROJECT_ID:
      $POMS_DATA_DISPATCHER_DATASET_QUERY:
      $POMS_DATA_DISPATCHER_PARAMETER:
    
  
  Setting Up Configuration Files


In configuring Data Dispatcher/Metacat, some vital environment variables in your launch scripts and campaign configuration (.cfg) files need attention. They encompass:


  
    Minimum Required Environment Variables for POMS and fife_wrap:
    
      Note: The following information can be included in your login script.
    
    
      Variables used by fife_wrap at submission time for authentication with Metacat and Data Dispatcher clients, and for project retrieval/creation:
        
          Always required:
            
              $X509_USER_PROXY
              Employed for login/authentication with Metacat and Data Dispatcher client.
            
          
          Required if not set in POMS or fife_wrap:
            
              These variables might be automatically provided via POMS and fife_wrap in future releases.
            
            
              $METACAT_SERVER_URL
                
                  Directs the Metacat client for API calls.
                
              
              $METACAT_AUTH_SERVER_URL
                
                  Used for authentication and login.
                
              
            
          
        
      
    
  
  
    Environment Variables Generated and Used by POMS
    
      Upon the initiation of a campaign or a campaign stage, POMS will generate some, or all, of the following fields:
        
          
            $POMS_DATA_DISPATCHER_TASK_ID:
            
              This identifier will always be generated by POMS, and is unique to each data dispatcher submission.
            
          
          
            $POMS_DATA_DISPATCHER_PROJECT_ID:
            
              This is provided by POMS in every scenario EXCEPT:
                
                  Stages employing the ‘Draining’, ‘Multiparam’, or ‘List’ Split Types only if the user inputs a “param” value in the data_dispatcher_dataset_query field, as opposed to a project_id or a query.
                  For instance:
                    
                      [campaign_stage dd_sample_campaign_stage_1]
cs_split_type=list
data_dispatcher_dataset = [&#39;param: 01-20030-es&#39;, &#39;project_id: 23&#39;, query:&#39;files from namespace:name&#39;]
                      
                    
                  
                
              
            
          
          
            $POMS_DATA_DISPATCHER_DATASET_QUERY:
            
              This field will always be provided by POMS,
              and is utilized to establish a project within the wrapper if a project_id is not furnished, or if POMS does not initiate creation.
            
          
          
            $POMS_DATA_DISPATCHER_PARAMETER:
            
              This will be furnished by POMS when employing a split type as elaborated above for the ‘Draining’, ‘Multiparam’, or ‘List’ Split Types.
            
          
        
      
    
  
  
    Setting Up Configuration Files
    
      Begin with the configuration of the [global] section:
        
          [global]
dd_task_id = override_me
dd_project_id = override_me
dd_dataset_query = override_me
dd_param = override_me
          
          
            Note: The variables listed above are optional and can be named according to your preference. Ensure to include overrides in your param_overrides, for instance:
-Oglobal.dd_task_id=$POMS_DATA_DISPATCHER_TASK_ID
          
        
      
      Configure the [data_dispatcher] section:
        
          [data_dispatcher]
task_id = %(dd_task_id)s
project = %(dd_project_id)s
dataset_query = %(dd_dataset_query)s
parameter = %(dd_param)s
namespace = poms_test
query_limit = 5
load_limit = 5
user = %(account)s
          
          Note: Since most of these fields are defined in POMS, users
can consider most of this section as optional. However, it’s worth noting that defining a query or load limit here may affect your submission. Likewise, if you define one of these fields in POMS, it will take precedence over what is in your configuration file.
        
      
      Configure the [submit] section:
        
          [submit]
e...
e_4 = POMS_DATA_DISPATCHER_TASK_ID
e_5 = POMS_DATA_DISPATCHER_PROJECT_ID
e_6 = POMS_DATA_DISPATCHER_DATASET_QUERY
e_7 = POMS_DATA_DISPATCHER_PARAMETER
e_n ... 
          
          Note: fife_launch and fife_wrap have been modified to automatically add the above environment variables to the jobsub_submit command during a POMS launch. That said, it is good practice to have these variable names in your job configuration file.
        
      
      Configure the [env_pass] section:
        
          [env_pass]
DATA_DISPATCHER_URL=https://metacat.fnal.gov:9443/hypot_dd/data
METACAT_SERVER_URL=https://metacat.fnal.gov:9443/hypot_meta_dev/app
DATA_DISPATCHER_AUTH_URL=https://metacat.fnal.gov:8143/auth/hypot_dev
METACAT_AUTH_SERVER_URL=https://metacat.fnal.gov:8143/auth/hypot_dev
          
          
            Note: these values may already be known by POMS or fife_utils, and may not be required unless trying to use a specific server. Check with our POMS if you have questions about metacat/dd servers.
          
        
      
      Configure the [job_setup] section:
        
          setup_1 = metacat
setup_2 = data_dispatcher
          
          
            Note: the UPS packages above are available in cvmfs, and require python3.7 or higher to function properly. In the future, UPS will be phased out, and replaced by spack.
          
        
      
    
  

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/data_dispatcher/environment_setup/">Environment Setup</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="POMS Campaign_setup-----
  By Campaign INI File    
      Section: [campaign]
      Section: [campaign_stage]
    
  
  By GUI Campaign Editor    
      Campaign
      Campaign Stage
    
  


Historically, campaigns in POMS have been configured to run exclusively on SAM. However, with some experiments transitioning to Data Dispatcher while others continue to utilize SAM, it’s imperative for experimenters to specify the desired Data Handling Service for each campaign. By default, POMS is configured to operate with SAM, but this setting can be altered during the campaign creation or editing process as follows:
By Campaign INI File

  
    Section: [campaign]
    
      
        Designate: data_handling_service = data_dispatcher

          [campaign]
experiment=hypot
poms_role=analysis
name=dd_sample_campaign_1
data_handling_service=data_dispatcher
state=Active
campaign_keywords={}
campaign_stage_list=dd_sample_campaign_stage_1
        
      
    
  
  
    Section: [campaign_stage]
    
      Designate ONE of the following:
      data_dispatcher_dataset_query = “some mql query” (as string)
      data_dispatcher_project_id = your_project_id (as integer)
          [campaign_stage dd_sample_campaign_stage_1]
  software_version=
  output_ancestor_depth=1
  cs_split_type=drainingn(5)
  data_dispatcher_dataset_query=files from :
  data_dispatcher_project_id=
  completion_pct=100.0
  merge_overrides=False
  stage_type=test
  default_clear_cronjob=False
        
      
    

    
      Note: The above example defined both data_dispatcher_dataset_query and data_dispatcher_dataset_project_id  for informational purposes only
      
        Only one of these should be used for each campaign stage. See usage notes below for details.
      
    
  


By GUI Campaign Editor

  
    Campaign
    
      Double click on your campaign
        
          Select data_dispatcher as the data_handling_service by selecting it from the dropdown.
          Click Save
        
      
    

    
      
      
          
          Figure 1: Campaign Editor, note the dropdown menu next to data_handling_service
      
  
  





  
    Campaign Stage
    
      Enter data_dispatcher_dataset_query OR data_dispatcher_project_id
      Click Save
        
          By selecting data_dispatcher as the data_handling_service, the remaining campaign setup will follow a flow similar to what users are accustomed to, with a few key differences:
          
            sam_dataset_or_split_data is grayed out and cannot be modified.
            A new field data_dispatcher_dataset_query is now used in place of the sam_dataset. IMPORTANT: this should be an MQL query, not a dataset.
            A new data_dispatcher_project_id exists and takes a numerical value, which is used as the project id for each submission for this stage.
          
        
      
    

    
      
      
          
          Figure 2: Campaign Stage Editor, note the new fields: *data_dispatcher_dataset_query* and *data_dispatcher_project_id*
      
  
  

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/data_dispatcher/poms_campaign_setup/">POMS Campaign_setup</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Split Types and Data Dispatcher Fields-----
  Notes on usage of data dispatcher fields:    
      data_dispatcher_project_id
      Example of data_dispatcher_project_id override trait
      data_dispatcher_dataset_query
    
  



  Some of the split types in POMS are essentially deprecated due to the ability to utilize complex MQL queries to specify files within a project. However, split types will continue to work with Data Dispatcher the same as they do with SAM.
  
    To utilize split-types for your campaign stages, you can set them up the same as you would with a SAM campaign. This can be done via ini file, or the campaign editor.
    If using a split type, ensure that:
      
        The “data_dispatcher_project_id” field IS blank.
        The “data_dispatcher_dataset_query” IS NOT blank, and is in the format required by the selected split-type.
      
    
  


Notes on usage of data dispatcher fields:


  Stages require either a data_dispatcher_dataset_query OR data_dispatcher_project_id.


data_dispatcher_project_id


  
    An Integer representing an existing project id.
  
  
    Consider this field to be a project_id override, meaning that POMS will disregard other configuration details such as split type, and data_dispatcher_dataset_query, and only submit the data dispatcher project defined in the data_dispatcher_project_id field.
  
  
    This field should not be used if you are utilizing a split_type for your campaign/campaign stage because projects cannot be altered after they are created. If using a split type, please provide a data_dispatcher_dataset_query instead.
  
  
    This field is especially helpful if experimenters want to restart, re-submit, or continue processing a specific project, rather than create a new one.
  


Example of data_dispatcher_project_id override trait


  In the example below, POMS will use the project with id=42 for each submission



  data_dispatcher_dataset_query = files from poms_sample:some_dataset
data_dispatcher_project_id = 42
  



  In the next example, POMS will define a new project with the files returned from running ‘files from poms_sample:some_dataset’



  data_dispatcher_dataset_query = files from poms_sample:some_dataset
data_dispatcher_project_id = None
  



  Note: To reduce confusion, the ‘data_dispatcher_project_id’ field may be renamed to “data_dispatcher_project_id_override” in the future.


data_dispatcher_dataset_query


  
    An mql query (string) that serves as the baseline for the files to be used within a data dispatcher project.
  
  
    Instead of merely entering a dataset name as was done with SAM, experimenters are now required to provide an MQL query to establish a baseline project. POMS may then reference and modify this baseline to comply with the requirements of a split type, or dependency launch.
  
  Utilizing an MQL query rather than a dataset presents numerous advantages for POMS users, including:
  
    Comprehensive: All previous POMS data dispatcher submissions for a given campaign/stage are visible through a simple and intuitive UI. Project history can be filtered on the campaign/campaign_stage details pages. This UI encompasses the campaign, stage, and submission information, alongside the query utilized, project status, project files, and their statuses within a particular project submission.

    
      
        Project Details are delineated on the left-hand side, and are filtered to the current campaign/campaign stage. Additional filters include project id, owner, and state.
      
      
        Project files are situated on the right-hand side, and are displayed by selecting “View Handles” on the desired project.

        
          Files can be sorted by name, namespace, and state.
          The background color on each file’s card header indicates its current state:
            
              Green: Done
              Red: Failed
              Orange: Reserved
              Yellow: Initial
            
          
        
        
      
      
          Figure 3: Campaign Project Submission History :  This UI is available on the data_dispatcher_overview, campaign_overview, and campaign_stage_info pages.
          
      
  
      
    
  
  
    Versatile: Queries empower experimenters to create highly customized file sets for project submissions, offering the flexibility to alter them at any time and include files from multiple namespaces/datasets:
  
  
    Simple: Potentially reduces the need for certain split types:

    
      
        In the SAM setup, some split types, such as the ‘byrun’ split type, filter input datasets based on metadata like ‘run_number’, while others might use the creation date or other metadata.
      
      
        With Data Dispatcher, employing an MQL query as the baseline permits many of these additional configurations to be bypassed by simply appending filters to the baseline query, thereby streamlining the process.

        
          data_dispatcher_dataset_query = files from poms_samples:some_dataset where core.run_number = 1202 and created_timestamp &gt;= ‘2023-08-01’ and created_timestamp &lt;= ‘2023-08-31’
        
      
    
  
  
    Fast: Facilitates rapid launch of recovery, dependency, or custom submissions in the event of an error with the initial query, or rather than waiting for POMS to submit a follow-up job:

    
      
        Ex 1: Should some files be missed in a submission, and the project is already halfway complete, there’s no need to create a new dataset or relaunch every file. Experimenters can effortlessly update the query to include specific files, launch, and monitor both projects in real-time:

        
          data_dispatcher_dataset_query = fids 12345, 67891, …
        
      
      
        Ex 2: Suppose your dataset is missing some files from a parent dataset, and POMS encountered an issue launching a dependency submission. Your team urgently needs this task completed and is awaiting the resolution of the bug by the POMS developers.

        
          
            Instead of waiting, your team has the option to create a temporary dependency stage, or temporarily alter the data_dispatcher_dataset_query of an existing stage to obtain the necessary files promptly:

            
              data_dispatcher_dataset_query = parents(files from poms_sample:some_dataset)
Or
data_dispatcher_dataset_query = parents(fids 12345, 678910,… )
            
          
        
      
      
        For guidance on constructing MQL queries, refer to: Metadata Query Language
      
    
  

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/data_dispatcher/split_types_and_data_dispatcher_fields/">Split Types and Data Dispatcher Fields</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Tracking Submissions-----
  Tracking via UI Elements    
      1. File Status Definitions
      2. Campaign Stage Submissions Display Enhancements
      3. Submission Relaunch with Specified Project ID
      4. Navigation to Metacat Webserver for File/Dataset Details
    
  


As highlighted earlier, real-time tracking of data dispatcher project submissions is facilitated through POMS. This capability is enabled via several avenues, including the newly integrated Data Dispatcher UI components found on campaign, stage, and submission details pages. Moreover, akin to SAM submissions, you can access submission statistics and review output files seamlessly. This feature amplifies transparency and enables a dynamic monitoring framework for all your data handling operations.

Tracking via UI Elements

Transitioning to the data dispatcher framework has been designed to be intuitive for the experimenter. The idea is to ensure that the learning curve is minimal and you don’t have to traverse a new learning trajectory just to adapt to this system. Here’s a comforting thought: the familiarity in user interaction has been retained. The pages you’ve known retain their look, feel, and behavior as with SAM.

  
    Tracking submissions? It’s done on the same pages as before.
    The file stats? They are located in the same areas, and on the same pages as before.
    All the previous pages and UI elements? They continue to display the same types of data as before.
  


However, while the UI maintains a semblance of the former system, there are some subtle yet significant distinctions when you’re operating under the data dispatcher as opposed to SAM:

1. File Status Definitions

  Unlike SAM, Data Dispatcher operates with a slightly different set of file statuses. Here are the key differences:
    
      The “located” status isn’t utilized in Data Dispatcher. Instead, a timeout mechanism is employed when fetching a file from the defined RSE (Replica Storage Element). If the file isn’t found within the stipulated time, it’s skipped and POMS (Production Operations Management System) tags it as “Unknown”.
      Leveraging the quick and easy state determination of files in a Data Dispatcher project, a “Submission % Completed” field is provided.
        
          This feature shines especially with split types, where a large project exists but only a portion of the files are to be processed. The field reflects the completion percentage of the specified submission, not the project in its entirety.
        
      
      A file is marked as “initial” upon definition but prior to processing. POMS regards files in the “initial” state as “Not Submitted”.
      The status transitions to “Reserved” when Data Dispatcher fetches a file.
      Post-processing, a file is tagged as “done” if the processing is successful.
      Conversely, a failed processing attempt tags the file as “failed”.
        
          Additionally, a flag is associated with failed files to indicate whether a retry is feasible. However, the retry control does not reside with POMS.
        
      
    

    
      
      
          Figure 4: Submission Details * File Stats: This picture gives an example of a new project that has not yet begun processing. Note that this project would likely fail because the files defined in the dataset do not include replicas * which is an indicator that they cannot be located in the designated RSE (Not shown).
          
      
  
  


2. Campaign Stage Submissions Display Enhancements

  A new column has been introduced in the grid below to indicate the Data Handling Service utilized for the submission—either SAM or Data Dispatcher.
  The Status fields (both History and Current) have been updated to reflect one of three states: “Created”, “Completed”, or “Completed with failures”. Unlike with SAM, POMS doesn’t interface with FERRY to ascertain submission statuses when Data Dispatcher is in play. Instead, the real-time tracking of these statuses is enabled, as depicted in Figure 3.
    
      
      
          Figure 5: Campaign Stage Submissions: This picture gives an example campaign stage that had been submitted several times.
          
      
  
  


3. Submission Relaunch with Specified Project ID

  Should you encounter failed files, wish to restart your project/run, or have any other reason to relaunch, this action can be accomplished via the ‘Relaunch’ button, as illustrated in Figure 6 below.
    
      Initiating a campaign stage submission that is defined through a dataset query will engender a new data dispatcher project, encompassing the same files but in an ‘initial’ state.
      An alternative method to simulate a “relaunch” is by updating the “data_dispatcher_project_id” field within the GUI editor, ensuring submissions are always tied to the specified project id.
    
    
      
      
          Figure 6: Displays the Submission Details UI of a Data Dispatcher Campaign
          
      
  
  


4. Navigation to Metacat Webserver for File/Dataset Details

  Upon clicking the links provided in the file stats (refer to Figure 4), you will be directed to your Metacat webserver where detailed information regarding the file/dataset is available.
    
      
      
          Figure 6: Metacat Webserver file details: Navigating here by clicking on any of the files returned in our file stat queries will display relevant metadata about the selected file.
          
      
  
  

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/data_dispatcher/tracking_submissions/">Tracking Submissions</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Harnessing Data Dispatcher with POMS - Your Campaign Command Center-----
  Introducing Data Dispatcher for POMS!
  Why Transition to Data Dispatcher from SAM?
  Prerequisites
  Instructions for Setting Up and Using Data Dispatcher on POMS:


Introducing Data Dispatcher for POMS!

  
    Data Dispatcher is one of three new systems in place that collaboratively manage the storage/location of files and metadata, and orchestrates the execution of projects based on a given project id, dataset, or query.
  
  
    In our setup, Data Dispatcher leverages Metacat for metadata cataloging, and Rucio for file lookup.
  
  
    POMS is now adept at managing campaigns and their subsequent stages utilizing Data Dispatcher, shifting away from the SAM platform.
  
  
    Our implementation aims to maintain consistency with the SAM utilization approach, albeit with a few distinctions which are elaborated upon in the sections below.
  


 

Why Transition to Data Dispatcher from SAM?


  
    SAM, being an older platform, necessitates numerous steps to ascertain the status of a project/definition and lacks diversity in achievable functionalities.
  
  
    Data Dispatcher empowers experimenters to monitor job updates in real-time without imposing a significant load on the existing system. Moreover, POMS furnishes a user interface displaying crucial details of all submissions made through it.
  
  
    Projects in Data Dispatcher can be swiftly restarted, duplicated, or altered without adhering to a strict naming convention. Attributes can be appended to a project to provide local information like campaign, stage, submission, or split type used, which is easily accessible and can be queried if necessary.
  


Prerequisites


  Ensure Rucio is set up for your experiment to define the physical location of files.
  Experimenters need to have accounts on Metacat:
    
      Provide thePOMS Admin with the Metacat server URL and auth server URL, which will be utilized by POMS.
      Your Metacat server should either have an account with admin privileges for POMS, or you should create a group for POMS which every experimenter should be a part of (can be segregated based on analysis/production roles).
      For transitioning to Data Dispatcher on POMS, reach out to the  POMS Admin for onboarding your experiment/group.
    
  


Instructions for Setting Up and Using Data Dispatcher on POMS:

  Environment Setup
  Poms Campaign Setup
  Split Types and Data Dispatcher Fields
  Tracking Submissions

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/data_dispatcher/">Harnessing Data Dispatcher with POMS - Your Campaign Command Center</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Campaign Time Bars Help-----
This shows each recent Task (which is started by a job submission and is a roll-up of the states of the one or more Jobs in the Task) in the Campaign as a colored timeline in the overall time window of the screen. Status of the task is shown as a colored region, with a key showing the colors for each status. 
Status values are defined in the Glossary. A small table also shows overall job information about the campaign, each number is a link to a jobs table (see Job Table Help) showing the jobs contributing to that total. Clicking on any of the zero values in the table gives you an empty jobs table, which is particularly uninteresting.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/campaign_time_bars_help/">Campaign Time Bars Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Job Efficiency Histo Help-----This page shows the jobs as a sideways histogram by efficiency, with 10% wide buckets labeled with the percentage efficiency range.



Each bar can be clicked through to see a job table of jobs with that percent efficiency range in this campaign.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/job_efficiency_histo_help/">Job Efficiency Histo Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="File Info By Submission Help-----
  jobsub_job_id
  project
  date
  submitted
  delivered (SAM:logs)
  consumed
  skipped
  unk.
  w/some kids declared
  w/all kids declared
  w/kids inflight
  w/kids located
  pending

This is a table for the given time window (default 1 day) for the given campaign.
It shows each job submission, and counts of files handled by each. Each count is a click through to show the list of files, and the SAM query to get the list.

The page has the following columns:

jobsub_job_id

Jobid of the submission – click through to see the time bars for the jobs, and to click through to a triage page for the jobs.

project

SAM Project name (or playlist file?) for the submission

date

date of the submission

submitted

Number of files in dataset/playlist.

delivered (SAM:logs)

Files delivered according to SAM and according to the log scraper.

consumed

Files listed as consumed in SAM

skipped

Files listed as skipped in SAM

unk.

w/some kids declared

Files we have some outputs declared for

w/all kids declared

Files we have some outputs declared for

w/kids inflight

Count of files “in flight” – that is output files we saw in the logs that are not declared in SAM yet.

w/kids located

Count of files with all kids declared with locations.

pending

Count of files without all kids declared with locations.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/file_info_by_submission_help/">File Info By Submission Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Sample Workflow-----This page is currently in development.

If you are in urgent need of help regarding this page, please contact: ltrestka@fnal.gov
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/sample_workflow/">Sample Workflow</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Dashboard Help-----This screen shows status of services, and has a  menu to get elsewhere.

The status display can be clicked open to see subcomponents:



This shows a toplevel component whose status is Good (green) and is
composed of 2 subcomponents, zero of which are failed. And then
each of the two subcomponents are based on monitoring statistics
from the pages reachable by the link.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/dashboard_help/">Dashboard Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Oidc Auth Help-----This is a feature that may come to fruition in a future poms release.

The basic use is for Analysis users to be able to acquire a vault token via the POMS webservice, rather than with the use of poms_client.

Currently, poms_client uses htvaulttoken to get a vault token, where the user receives an OIDC/OIDC-Kerberos link to follow.

Once the user authenticates via the link provided, poms_client receives a vault token from the vault server, and uploads it to the poms #UPLOADS directory. This can be seen as an Analysis user on the main menu under “User Data” -&gt; “Uploaded Files”
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/oidc_auth_help/">Oidc Auth Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="How To Make Snow Request For Poms-----
  Step 1.
  Step 2.
  Step 3.
  Step 4.
  Step 5.


In order to open a request, users may go to the SNOW ticket portal:

  https://fermi.servicenowservices.com/


Step 1.

At the web portal, you need to authenticate providing your service credential.



Step 2.

Then in the left menu, the option Scientific Computing Services may be selected.



Step 3.

After, you should scroll in the right menu until you find Scientific Production Service and you may select POMS.



Step 4.

Then, the portal will present a description of the service, at the right, you may find the Get Help menu. In this box, users may choose the option Submit a request to service providers



Step 5.

Finally, you may fill the form. Please, try to describe in detail your request.

Requester’s Name: Your name will be here.
What service is the request related to?: This value should be “POMS”.
Virtual Organization: Name of the experiment making the request. If not available the closer description possible to it.
Specify urgency of your request: Urgency level of your request.
Enter a short description of your request:** Short description of your request
**Please enter the details of your request here: Detailed description of your request.



">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/how_to_make_snow_request_for_poms/">How To Make Snow Request For Poms</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Launch Jobs Help-----This page is currently in development.

If you are in urgent need of help regarding this page, please contact: ltrestka@fnal.gov
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/launch_jobs_help/">Launch Jobs Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Tutorial Outline-----
  Front page
  First Time Setup    
      Before we start
      Config Overview
      Launch template
      Job Type
      Campaign Layer
      Actually Launching
      Watching what goes on
      Debugging launch problems
    
  

Front page


  Service status
  Hold/allow jobs


First Time Setup

Before we start

  make sure you can
    
      log in somewhere
      kdestroy (so you arent’ relying on your krb5 creds)
      setup things
      submit a small job of this type
      with above specifying on command line
    
  
  
    
      software version,
    
  
  
    
      SAM dataset
    
  
  
    
      number of jobs
    
  
  Have a log/detailed notes of same.


Config Overview

(yes it needs a setup wizard…)

Three components, in left menu, to setup:


  Launch Template
    
      “To prepare to launch jobs I ssh into xxx and source yyy and zzz”
    
  
  Job Type
    
      “To submit a monte carlo job, I run exp_launch.py –dataset fred”
    
  
  Campaign Layer
    
      “This is Fred’s monte carlo run with version x and configs y”
    
  


Launch template

“To prepare to launch jobs I ssh into xxx and source yyy and zzz”


  left menu
  Compose Launch Template
  pick experiment (if not there, file ticket)
  Click [ + Add ]
  Give it a name (i.e. exppro_on_expgpvm02), a hostname (i.e. expgpvm02) , and account (i.e. exppro)
  Fill in a setup entry like “source /some/exp/setup; setup exp_sw %(version)s”
  NOTE: use %(version)s if you’re setting up some version, so POMS can fill it in with the correct version from a given campagin layer later.
  hit Submit
  
    Bonus points: ssh into that account, add

    poms/cd/pomsgpvm01.fnal.gov@FNAL.GOV
    
  
  to .k5login


Job Type
“To submit a monte carlo job, I run ‘exp_launch.py –mc –dataset fred’”

  left menu
  Compose Job Type
  pick experiment (if not there, file ticket)
  Click [ + Add ]
  Give it a name (i.e. exp_mc_type1)
  list Output File Patterns (i.e. mc_out%.root) of outputs that will get declared to SAM
  Launch script
    
      give it a launch script to run, that will have parameters passed to it.
      if your usual launch script doesn’t accept command line parameters for, say, dataset definition, etc. you need to put in a shell function that does, then call that…
      I recommend fife_launch :-)
    
  
  Definition Parameters
    
      click [/] (w/ pencil) to edit
      this is a mechanism to define things that might get overridden further, so it’s slightly tricky to do right the first time; We’ll talk more about this later.
      left hand “Key” column must be unique
      use [+] button to add more pairs.
      name value pairs that make parameters to script
      If its like -O sect.var=value split it as [-O sect.var=] [value]
      if option needs space after it, include in box [-g ] [group]
    
  
  Recovery Launches
    
      click [/] (w/ pencil) to edit
      Pick recovery type for up to 5 recoveries.
      recommend 1. consumed_status 2. pending files
      hit [Accept]
    
  
  hit [Submit]


Campaign Layer
“This is Fred’s monte carlo run with version x and configs y”

  left menu
  Compose Campaign Layer
  pick experiment (if not there, file ticket)
  Click [ + Add ]
  Give it a name i.e. “Spring16CosmicsMC”
  List VO Role (i.e Production or Calibration…)
  Software version – exp software version that will be in output metadata
  Dataset – full input dataset (i.e. mc config files, raw files to process, etc.)
  Dataset split type
    
      If Dataset is large; and not defined as “draining”..
      usually mod(k) to split into k pieces is good
      new(window=2d,start_time=123456) for two days of data per submission
      let us know if other split types are useful (i.e. by subrun?)
    
  
  Completion type/percent – (i.e. Located @ 95% (if using SAM))
  Parameter Overrides
    
      edit with [/] (w/pencil) click, as with Job Types, above
      here is where picking good parameters in the Job Type pays off
      If something needs to be different/added to the launch in the Job Type for this campaign, you can add it here
      anything with matching Key here overrides one from Job Type
      new Keys are added to options
      hit [Accept] when done
    
  
  Depends On
    
      Will do more later, but:
      edit with [/] (w/pencil) click
      Can pick other exisitng Campaign layer for your experiment (but not yet, as we don’t have any)
      Can pick this campaign layer, means launch another batch as each one completes.
      Specify particular output file pattern from that campaign’s output you use as input.
      hit [Accept] when done
    
  
  Launch Template
    
      at the moment we have 1 to choose from, can pick any you have, fields show up.
    
  
  Job Type
    
      at the moment we have 1 to choose from, can pick any you have, fields show up.
    
  
  Hit [Submit]


Actually Launching

  Launch by hand
    
      left menu
      Active for exp
      Click on campaign layer name
      Launch Campaign Jobs Now
    
  
  Launch via cron (show uBooNE Electron Lifetime for example)
    
      left menu
      Active for exp
      Click on campaign layer name
      Clikc on Schedule Future Job Launches
      Fill in entry form for crontab
    
  


Watching what goes on

  left menu
  Active for exp
  Click on Campaign Layer name
  Several options
    
      By submission-jobs: (control?)-click Submission Time Bars
    
  
  
    
      Page shows time bars for each submission
    
  
  
    
      Can click through to jobs from that submission
    
  
  
    
      Can click through again to job triage
      By submission-files: Campaign Submission Files
    
  
  
    
      Can click through to specific file listings
    
  


Debugging launch problems

  Make a debug Job Type
    
      clone existing one
      name it Debug-xxx
      stick an “printenv ; echo” in front of command you usually run
      switch your campaign to use the Debug-xxx Job Type
    
  
  launch may be working due to kerberos ticket interactively
    
      log into account
      kdestroy
      test setup/launch using exp. proxy
    
  

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/tutorial_outline/">Tutorial Outline</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Calendar Help-----POMS interfaces to the services data at https://fifemon.fnal.gov to determine if there are any issues or service downtimes based on specific criteria. If an interruption in service is detected, the data gets stored in the POMS database. This calendar represents the downtimes recorded. Related service items are grouped together and are color coded; look at the legend in the screenshots to see this. Red is the default color for items that do not belong to any particular category.

Not only is this a representation of ACTUAL service disruptions but also of SCHEDULED planned downtimes, which users can create. Simply click on a day in the calendar, and follow the prompts. The default span for a downtime is the entire day, however this can be modified by dragging and dropping the start and end times around in the day and week views. Take note that you can also move a downtime from one day to another by simply dragging and dropping the item in the month view. Users can not create their own service name for a SCHEDULED downtime, it has to be a service that POMS knows about.

Only SCHEDULED downtimes can be modified.

If you prefer, you can also click on a SCHEDULED downtime to modify its values.

The main purpose of this calendar is to help users triage their jobs.



Here is an overview of what the calendar looks like. You can curse through the month/week/day by using the left and right arrows that appear below the legend, dependent on the category (month/week/day) selected on the mid top right.



Here we illustrate creating a scheduled downtime for May 5, 2016 by simply clicking on the day itself. A popup appears showing us a list of available services to create a scheduled downtime for. Go ahead and copy the one you want, and select “Close”.



Paste that value in the text field, and select “OK”.



Here you are getting the status of the update. If all went well, you should see an “Ok.” message.



We are now done, and can see our newly created scheduled downtime set for May 5, 2016.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/calendar_help/">Calendar Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Launch Template Edit Help-----
  Name
  Host
  Account
  Setup


This page lets you configure a launch template, which specifies where you log in and what you setup to launch jobs.

First you pick your experiment from the pulldown, then you fill out the form, and hit “Submit”

The account in question will need the following .k5login entries:

poms/cd/fermicloud045.fnal.gov@FNAL.GOV
poms/cd/pomsgpvm01.fnal.gov@FNAL.GOV
&lt;YOUR KERBEROS USERNAME&gt;@FNAL.GOV


You MUST add your default principal to the .k5login file if the .k5login file exists. So if you’re creating a .k5login file for the first time don’t forget to add your account name in addition to the poms ids. Your Fermilab username must be lower case and the FNAL.GOV must be uppercase.

Name

Campaign identifying string, something like “Generic experiment X setup q1_2_3 v1.2.3”

Host

Host name like “some_node.fnal.gov”

Account

Account name

Setup

A set of shell commands setting up the environment for campaign to run. This will have Variable Substitution   performed.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/launch_template_edit_help/">Launch Template Edit Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Submission Details Help-----This page gives you pretty much all the available information about a given Submission.

The top box gives you the internal Submission id number, the jobsub-job-id, and the name, id and link to the Campaign Stage and Campaign the submission is associated with.

The Information box tells you how/why it was launched, and has links to the launch script output, and possibly links to related information in Landscape, SAM, and job logs on the jobsub_submit servers.

The Actions box has buttons/forms for various actions depending on the status of the submission:


  If the submission is Idle or Running, buttons to hold/release/kill the running jobs
  If the submission is Completed but not Located a “fast forward” button to kick it ahead to Located
  If the submission is Located, buttons to re-launch the job entirely
  If teh submission is completed or Located, a one-line form to launch a recovery job
    
      A pulldown to pick the type of recovery
      Then a button to actually fire the launch
      Many of these recovery types only work if the submission had a related SAM project.
    
  


The History box shows the times when POMS detected state transitions of the submission

The remaining boxes show details of the snapshots of the Submission, Campaign Stage, Job Type and Login/Setup associated with it made at the time of the launch (as opposed to what they may be set to now..)
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/submission_details_help/">Submission Details Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="How To Use Poms-----
  How to access to the POMS services    
      You need to do some configuration before you launch jobs. This a three steps process, following the links under Configure work in the left menu of POMS webpage.        
          1) Compose Launch template
          2) Compose Job Type:
          3) Compose the campaign stage:
        
      
      Launch the job submission        
          How to launch the jobs:
        
      
      Files
    
  

In order to be able to use POMS you need to be affiliated with a Fermilab experiment and have a computer account at Fermilab.

How to access to the POMS services

Access to the following URL https://pomsgpvm01.fnal.gov/poms/ and use your Fermilab services credential.

You need to do some configuration before you launch jobs. This a three steps process, following the links under Configure work in the left menu of POMS webpage.

1) Compose Launch template

This template can be reused and re-edit later. You can re-use, clone, and modify for different campaigns. So you can use the same template for different processing campaigns. As a user, you choose your experiment and push the bottom “add” in order to create a new template. Those are also useful for other members of the experiment. You need to fill:


  Name: Define the name of your template (MonteCarlo)
  Host: Define the interactive node or machine you are going to use to launch your jobs (novagpvm01)
  Account: Define the user account for the launch (eg. {USER}, novapro, minervapro, minervacal, uboonepro, etc )
  setup: You define the environment variable, setups, or scripts that you usually setup on your own machine (e.g. setup_nova, launch script)


The Account in question will need the following .k5login entries:

poms/cd/pomsgpvm01.fnal.gov@FNAL.GOV


2) Compose Job Type:

After you fill the job type format, you can re-use, clone, and modify for different campaigns. Those are also useful for other members of the experiment.


  Name: A name that describes the kind of campaign you are running (eg. Nova raw2root keepup FD, rock_neutrinoMC, minerva_cal)
  input files per job: The expected number of input files per job, fill the field as 0 if you are not sure do not leave it empty (eg. 1 if you just receive the .raw data as an input file)
  output files per job: The expected number of output files per job, fill the field as 0 if you are not sure do not leave it empty (eg. 3 if you expected to produce one .root .log .json file per every input file )
  output file patterns: The output pattern you are interested in your campaign (eg. %.root)
  Launch Script: In this field, you need to put the script that you run to submit jobs in your machine.
  Definition Parameters: The arguments your script (included in Launch script) use for the submission.
  Recovery Launches: This field defines your recovery launches in case needed. Your options are: added_files, consumed_status, pending files, proj_status


3) Compose the campaign stage:

This stage define your specific campaign (related with a specific production task), in this step you use the launch template and the job type defined in the previous steps (or you can use an existing one)


  Name of the campaign: A name that describes your campaign properly (eg. NOvA Raw2Root Keepup fardet S16-11-02)
  VO role: The role in the VO (eg. analysis, production)
  State (active or inactive)
  Software Version: In your experiments, you can have different versions of your code, this field help you to track the one that you use for that specific campaign.
  DataSet: The SAM definition (dataset) that you want to process, you can also define that in your script then you leave this field as none
  DataSet split type: POMS can split the dataset in order to do sub-dataset and make the tracking task easier. It is also useful to prevent problems handling huge datasets inside SAM projects.
  Completion type: Then the user have two options: located and complete.



  Located: This option suggest that your completed threshold (for launch dependence campaigns) depends on the number of job with all their files located. A located file reference a file which has children declare on SAM.
Complete: This option suggest that your completed threshold (for launch dependence campaigns) depends on the number of jobs that ended with error code 0 but it does not check if the output files are located. A located file reference a file which has the children declare on SAM.



  Completion pct: it is the percentage of completion of jobs that you define to determine that specific campaign is successful (complete).
  Parameters override: This field is useful if you want to change the ones that are in the template
  Depends on: If your campaign depends on other campaigns. (eg. calibration can depend on RawtoRoot)
  Launch template: This field you just choose a template that you have already create in advance (description above)
  Job type This field you just choose a job type that you have already create in advance (description above)


IMPORTANT: It is important to keep in mind that until now the user just configures the campaign to launch but the submission has not happend. In order to submit jobs follow the step below.

Launch the job submission

How to launch the jobs:


  After Compose the campaign stage, in order to launch jobs, the user should go the campaign stages under Campaign Data (left menu) and click.
  Then you will see all the active campaign for the experiment(s) you belong.
  Clicking on the campaign name move you to the campaign info page where the user can monitor the status of the jobs that belong to that specific campaign.
  Clicking the bottom Launch Campaign Jobs Now the user can submit jobs for the specific campaign configuration.


Furthermore, the user can use the option Schedule Future Job Launches which provide a kind of “crontab” for schedule your submissions. The scheduled submissions are sent by POMS and there is not crontab in your interactive node (experiment machine).

Files

  POMS_ICARUS_SBND_2018_02_14.pdf

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/how_to_use_poms/">How To Use Poms</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Show Campaigns Help-----This page shows the current active campaigns and a table of job statistics for each one:



On the left are the experiment and campaign name, then a summary of active jobs at the
end of the time window shown, and then a summary of jobs completed in the time window
shown.

Each campaign name is a link to the campaign info page, which besides information about
the campaign, has links to perform actions related to the campaign.

Each of the job counts in the table is a link to a table showing the jobs that give that total.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/show_campaigns_help/">Show Campaigns Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Protodune-----
  Compose Launch template
  Compose Job Type (campaign definition):
  Compose the campaign layer:

In order to submit and monitor your campaigns through POMS, you will need to do three stages create compose a launch template, a job type, and a campaign stage. This example is specific to ProtoDUNE collaboration.

Compose Launch template

For compose a launch template you need to click on Compose Launch template (look image below). This template can be reused and re-edit later. You can re-use, clone, and modify for different campaigns. So you can use the same template for different processing campaigns. As a user, you choose your experiment and push the bottom “add” in order to create a new template. Those are also useful for other members of the experiment.



For this example, we would like to copy a previous template clicking on the icon shown by the red arrow.



Then you will have the chance to edit the template.



Name: Define the name of your template (MonteCarlo)
Host: Define the interactive node or machine you are going to use to launch your jobs. e.g. dunegpvm01
Account: Define the user account for the launch e.g. dunepro
Setup: You define the environment variable, setups, or scripts that you usually setup on your own machine

Compose Job Type (campaign definition):


After you fill the job type format, you can re-use, clone, and modify for different campaigns. Those are also useful for other members of the experiment.



You can copy the Job Type (template) in the same way it was done for the previous stage (clicking the icon)



Name: A name that describes the kind of campaign you are running.
Output file patterns: The output pattern you are interested in your campaign (eg. %.root)
Launch Script: In this field, you need to put the script that you run to submit jobs in your machine.
Definition Parameters: The arguments your script (included in Launch script) use for the submission.
Recovery Launches: This field defines your recovery launches in case needed.

Compose the campaign layer:


This layer defines your specific campaign (related with a specific production task), in this step you use the launch template and the job type define in the previous steps (or you can use an existing one). Then you can copy one of the campaigns forms and edit it for your own campaign.



You can edit the fields, there you will pick a launch template and a Job Type.



Name of the campaign: A name that describes your campaign properly
VO role: The role in the VO (eg. analysis, production)
State: Active or Inactive. Mark your campaigns as inactive if you do not want to see them in your main menu.
Software Version: In your experiments, you can have different versions of your code, this field help you to track the one that you use for that specific campaign.
DataSet: The SAM definition (dataset) that you want to process, you can also define that in your script then you leave this field as none
DataSet split type: POMS can split the dataset in order to do sub-dataset and make the tracking task easier. It is also useful to prevent problems handling huge datasets inside SAM projects.
Completion type: Then the user have two options: located and complete.
Located: This option suggests that your completed threshold (for launch dependence campaigns) depends on the number of job with all their files located. A located file reference a file which has children declare on SAM.
Complete: This option suggests that your completed threshold (for launch dependence campaigns) depends on the number of jobs that ended with error code 0 but it does not check if the output files are located. A located file reference a file which has the children declare on SAM.

Completion pct: it is the percentage of completion of jobs that you define to determine that specific campaign is successful (complete). Fill with a number (0-100]
Parameters override: This field is useful if you want to change the ones that are in the template
Depends on: If your campaign depends on other campaigns. (eg. mergeana depends on reco campaign)
Launch template: This field you just choose a template that you have already create in advance (description above)
Job type This field you just choose a job type that you have already create in advance (description above)
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/protoDUNE/">Protodune</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Campaign Deps Help-----This page is currently in development.

If you are in urgent need of help regarding this page, please contact: ltrestka@fnal.gov
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/campaign_deps_help/">Campaign Deps Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Editing Job Types-----
  Name    
      Input Files Per Job
      Output Files Per Job
      Output File Patterns
      Launch Script
    
  

This lets you set the commands to launch a job of a given type.

First you pick the experiment appropriately,then you choose an campaign from the list,
or click “[+]Add”

Then you get to pick the name of this definition, the launch script, and parameters to that
script that this job type uses.

Name

A name for this job type

Input Files Per Job

If you have a fixed number of input files per job, you can enter it here.

Output Files Per Job

If you have a fixed number of output files per job, you can enter it here.

Output File Patterns

A database-‘like’ , percent sign wildcard, file pattern that matches your output files. Being more specific than the default ‘%’ lets us distinguish actual output files from log files, etc.

Launch Script

The commands you will run to launch a job of this type. This will have Variable Substitution  performed.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/editing_job_types/">Editing Job Types</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Campaign Info Help-----This page gives you information on a given campaign, and
allows you to perform actions like:


  Job Efficiency Histogram – show jobs histogrammed in efficiency buckets, click through to jobs with that efficiency
  Day by Day Spreadsheet – Report of progress day by day for last week, with links off to jobs, files, etc. summarized in table.
  Submission Time Bars – show recent submissions as time bars, click through to jobs as time bars, and then through to individual job triage.
  Campaign Submission Files – show files processed by each recent submission
  Launch Campaign Jobs Now – trigger a job launch with the next dataset slice
  Kill Jobs for Campaign – kill any jobs currently running for this campaign from POMS
  Schedule Future Job Launches – setup cron job to click above link for you.

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/campaign_info_help/">Campaign Info Help</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Client Documentation-----
  Current Methods    
      campaign_rm (experiment, name, test=False, role=None, configfile=None):
      campaign_stage_submissions (experiment, role, campaign_name, stage_name, test=None, configfile=None, **kwargs):
      get_campaign_id (experiment, campaign_name, test=None, role=None, configfile=None):
      get_campaign_list (test_client=False, experiment=None, role=None):
      get_campaign_name (experiment, campaign_id, test=None, role=None, configfile=None):
      get_campaign_stage_id (experiment, campaign_name, campaign_stage_name, test=None, role=None, configfile=None):
      get_campaign_stage_name (experiment, campaign_stage_id, test=None, role=None, configfile=None):
      get_submission_id_for (campaign_stage_id, user=None, command_executed=None, input_dataset=None, parent_submission_id=None, submission_id=None, test=None, experiment=None, configfile=None):
      job_type_rm (experiment, name, test=False, role=None, configfile=None):
      launch_campaign_jobs (campaign_id, test=None, test_launch=None, experiment=None, role=None, configfile=None):
      launch_campaign_stage_jobs (campaign_stage_id, test=None, test_launch=None, experiment=None, role=None, configfile=None):
      login_setup_rm (experiment, name, test=False, role=None, configfile=None):
      modify_job_type_recoveries (job_type_id, recoveries, test=None, experiment=None, role=None, configfile=None):
      show_campaign_stages (campaign_name=None, test=None, experiment=None, role=None, configfile=None, view_active=None, view_mine=None, view_others=None, view_production=None, update_view=None)
      show_campaigns (test=None, experiment=None, role = None, configfile=None, view_active=None, view_inactive=None, view_mine=None, view_others=None, view_production=None, update_view=None)
      submission_details (experiment, role, submission_id, test=None, configfile=None):
      tag_campaigns (tag, cids, experiment, role=None, test_client=False):
      update_stage_param_overrides (experiment, campaign_stage, param_overrides=None, test_param_overrides=None, test=None, role=None, configfile=None):
      update_submission (submission_id, jobsub_job_id=None, status=None, project=None, test=None, experiment=None, role=None, configfile=None):
      uploaded_files_rm (experiment, filename, test=None, role=None, configfile=None):
      upload_file (file_name, test=None, experiment=None, role=None, configfile=None):
      upload_wf (file_name, test=None, experiment=None, configfile=None, replace=False, role=None):
    
  
  Deprecated Methods    
      update_session_experiment (experiment, test_client=False):
      update_session_role (role, test_client=False):
      campaign_stage_edit (action, campaign_id, ae_stage_name, pc_username, experiment, vo_role, dataset, ae_active, ae_split_type, ae_software_version, ae_completion_type, ae_completion_pct, ae_param_overrides, ae_depends, ae_launch_name, ae_campaign_definition, ae_test_param_overrides, test_client=None, configfile=None) experiment=None, role=None)
      campaign_definition_edit (output_file_patterns, launch_script, def_parameter=None, pc_username=None, action=None, name=None, experiment=None, recoveries=None, test_client=False, configfile=None)
      campaign_edit (**kwargs):
      register_poms_campaign (campaign_name, user=None, experiment=None, version=None, dataset=None, campaign_definition=None, test=None, role=None, configfile=None):
      job_type_edit (output_file_patterns, launch_script, def_parameter=None, pc_username=None,
      launch_template_edit (action=None, launch_name=None, launch_host=None, user_account=None, launch_setup=None, experiment=None, pc_username=None, test_client=False, role=None, configfile=None)
      get_task_id_for (campaign, user=None, command_executed=None, input_dataset=None, parent_task_id=None, task_id=None, test=None, experiment=None, role=None, configfile=None):
      launch_jobs (campaign, test=None, experiment=None, role=None, configfile=None):
    
  

The following methods are available in the poms_client package.

This documentation reflects version v4_2_0 of poms_client for v4_2_0 of POMS.

In addition to this, in v4_2_0, most informational page URL’s in the regular POMS interactive interface can be called with @&amp;fmt=json@ on the end, to get a JSON dump of the data on the page.

Current Methods

campaign_rm (experiment, name, test=False, role=None, configfile=None):


  Remove a campaign.


campaign_stage_submissions (experiment, role, campaign_name, stage_name, test=None, configfile=None, **kwargs):

Get a JSON dump of submissions to a campaign stage, like:

{
    &quot;campaign_name&quot;: &quot;fake demo v1.0  w/chars&quot;,
     &quot;stage_name&quot;: &quot;f eg v1.0 - w/chars&quot;,
     &quot;campaign_stage_id&quot;: &quot;1&quot;,
     &quot;data&quot;: {
         &quot;tmin&quot;: &quot;2019-09-09T15:18:10&quot;,
         &quot;tmax&quot;: &quot;2019-09-16T15:18:10&quot;,
         &quot;nextlink&quot;: &quot;/poms/campaign_stage_submissions/samdev/production?campaign_name=fake demo v1.0  w/chars&amp;stage_name=f eg v1.0 - w/chars&amp;campaign_stage_id=1&amp;campaign_id=890&amp;tmax=2019-09-23+15:18:10&amp;tdays=7&quot;,
         &quot;prevlink&quot;: &quot;/poms/campaign_stage_submissions/samdev/production?campaign_name=fake demo v1.0  w/chars&amp;stage_name=f eg v1.0 - w/chars&amp;campaign_stage_id=1&amp;campaign_id=890&amp;tmax=2019-09-09+15:18:10&amp;tdays=7&quot;,
         &quot;tdays&quot;: 7.0,
         &quot;tminsec&quot;: &quot;1568063890&quot;,
         &quot;depends&quot;: {
            &quot;1267&quot;: null
         },
         &quot;depth&quot;: {
            &quot;1267&quot;: 0
         },
         &quot;submissions&quot;: [
              {
                &quot;submission_id&quot;: 1267,
                 &quot;jobsub_job_id&quot;: &quot;23733516@jobsub02.fnal.gov&quot;,
                 &quot;created&quot;: &quot;2019-09-10T11:28:29&quot;,
                 &quot;creator&quot;: &quot;mengel&quot;,
                 &quot;status&quot;: &quot;Located&quot;,
                 &quot;jobsub_cluster&quot;: &quot;23733516&quot;,
                 &quot;jobsub_schedd&quot;: &quot;jobsub02.fnal.gov&quot;,
                 &quot;campaign_stage_name&quot;: &quot;f eg v1.0 - w/chars&quot;,
                 &quot;available_output&quot;: 10,
                 &quot;output_dims&quot;: &quot;ischildof:(  snapshot_for_project_name mengel-fife_wrap_20190910_112913_3600585  ) and create_date &gt; &#39;2019-09-10 11:28:29&#39; and  file_name like &#39;%root&#39; and version &#39;v1_2&#39;&quot;
             }
        ]
    }
}


get_campaign_id (experiment, campaign_name, test=None, role=None, configfile=None):


  Lookup a campaign’s id from its name.


get_campaign_list (test_client=False, experiment=None, role=None):


  Get list of campaigns for an experiment.


get_campaign_name (experiment, campaign_id, test=None, role=None, configfile=None):


  Get a campaigns name given its id.


get_campaign_stage_id (experiment, campaign_name, campaign_stage_name, test=None, role=None, configfile=None):


  Get campaign stage’s id from its name, and its campaign’s  name.


get_campaign_stage_name (experiment, campaign_stage_id, test=None, role=None, configfile=None):


  Get stage name from id.


get_submission_id_for (campaign_stage_id, user=None, command_executed=None, input_dataset=None, parent_submission_id=None, submission_id=None, test=None, experiment=None, configfile=None):


  Get a submission id for a new submission in a campaign and/or (with submission_id)  update information about the submission.


job_type_rm (experiment, name, test=False, role=None, configfile=None):


  Remove a job type.  This will only work if nothing is using it…


launch_campaign_jobs (campaign_id, test=None, test_launch=None, experiment=None, role=None, configfile=None):


  Launch a submission for the first stage in a campaign.


launch_campaign_stage_jobs (campaign_stage_id, test=None, test_launch=None, experiment=None, role=None, configfile=None):


  Launch a submission for a particular campaign stage.


login_setup_rm (experiment, name, test=False, role=None, configfile=None):


  Remove a particular login_setup configuration.  This will only work if nothing is using it…


modify_job_type_recoveries (job_type_id, recoveries, test=None, experiment=None, role=None, configfile=None):


  This lets you modify the recoveries for a given job type; the recoveries is a python object (or json dump of same) just as it comes in a workflow  .ini file dump
    
      i.e  @[[“proj_status”, [[“-Osubmit.memory=”, “2000MB”]]]]@  A list of recovery-type, option-override pairs.
    
  


show_campaign_stages (campaign_name=None, test=None, experiment=None, role=None, configfile=None, view_active=None, view_mine=None, view_others=None, view_production=None, update_view=None)


  Get json dump of the campaign stages in a campaign


show_campaigns (test=None, experiment=None, role = None, configfile=None, view_active=None, view_inactive=None, view_mine=None, view_others=None, view_production=None, update_view=None)


  Json dump data from the show_campaigns page.


submission_details (experiment, role, submission_id, test=None, configfile=None):

Json dump data from a submission details page.  Has lots of bits in it…

{
    &quot;experiment&quot;: &quot;uboone&quot;,
     &quot;role&quot;: &quot;production&quot;,
     &quot;tl&quot;: [
         {
            &quot;campaign_id&quot;: 1087,
             &quot;experiment&quot;: &quot;uboone&quot;,
             &quot;name&quot;: &quot;vito_prod_muminus_0-2.0GeV_isotropic_uboone&quot;,
             &quot;active&quot;: true,
             &quot;defaults&quot;: null,
             &quot;creator&quot;: 29,
             &quot;creator_role&quot;: &quot;production&quot;,
             &quot;campaign_type&quot;: null,
             &quot;campaign_keywords&quot;: null,
             &quot;tags&quot;: null,
             &quot;stages&quot;: [{
                    &quot;campaign_stage_id&quot;: 1791,
                     &quot;experiment&quot;: &quot;uboone&quot;,
                     &quot;name&quot;: &quot;reco2&quot;,
                     &quot;job_type_id&quot;: 783,
                     &quot;creator&quot;: 29,
                     &quot;created&quot;: &quot;2019-01-09T16:43:10&quot;,
                     &quot;updater&quot;: 29,
                     &quot;updated&quot;: &quot;2019-01-10T11:31:33&quot;,
                     &quot;vo_role&quot;: &quot;Analysis&quot;,
                     &quot;cs_last_split&quot;: null,
                     &quot;cs_split_type&quot;: &quot;None&quot;,
                     &quot;cs_split_dimensions&quot;: null,
                     &quot;dataset&quot;: &quot;None&quot;,
                     &quot;software_version&quot;: &quot;v07_07_00&quot;,
                     &quot;login_setup_id&quot;: 516,
                     &quot;param_overrides&quot;: [
                         [&quot;--stage &quot;, &quot;reco2&quot;],
                         [&quot;-Oglobal.sam_dataset=&quot;, &quot;%(dataset)s&quot;]
                     ],
                     &quot;test_param_overrides&quot;: [
                         [&quot;--stage &quot;, &quot;reco2&quot;],
                         [&quot;-Oglobal.sam_dataset=&quot;, &quot;%(dataset)s&quot;]
                     ],
                     &quot;completion_type&quot;: &quot;complete&quot;,
                     &quot;completion_pct&quot;: 95,
                     &quot;hold_experimenter_id&quot;: null,
                     &quot;creator_role&quot;: &quot;production&quot;,
                     &quot;role_held_with&quot;: null,
                     &quot;campaign_stage_type&quot;: &quot;test&quot;,
                     &quot;merge_overrides&quot;: false,
                     &quot;output_ancestor_depth&quot;: 1,
                     &quot;campaign_id&quot;: 1087,
                     &quot;experimenter_creator_obj&quot;: {
                        &quot;experimenter_id&quot;: 29,
                         &quot;first_name&quot;: &quot;Vito&quot;,
                         &quot;last_name&quot;: &quot;Di Benedetto&quot;,
                         &quot;username&quot;: &quot;vito&quot;,
                         &quot;last_login&quot;: &quot;2019-03-08T10:03:42&quot;,
                         &quot;session_experiment&quot;: &quot;uboone&quot;,
                         &quot;session_role&quot;: &quot;analysis&quot;,
                         &quot;root&quot;: false,
                         &quot;exp_expers&quot;: null
                     },
                     &quot;experimenter_updater_obj&quot;: {
                         &quot;experimenter_id&quot;: 29,
                         &quot;first_name&quot;: &quot;Vito&quot;,
                         &quot;last_name&quot;: &quot;Di Benedetto&quot;,
                         &quot;username&quot;: &quot;vito&quot;,
                         &quot;last_login&quot;: &quot;2019-03-08T10:03:42&quot;,
                         &quot;session_experiment&quot;: &quot;uboone&quot;,
                         &quot;session_role&quot;: &quot;analysis&quot;,
                         &quot;root&quot;: false,
                         &quot;exp_expers&quot;: null
                     },
                     &quot;experimenter_holder_obj&quot;: null,
                     &quot;experiment_obj&quot;: null,
                     &quot;job_type_obj&quot;: null,
                     &quot;login_setup_obj&quot;: null,
                     &quot;campaign_obj&quot;: {
                        &quot;name&quot;: &quot;vito_prod_muminus_0-2.0GeV_isotropic_uboone&quot;
                     },
                     &quot;providers&quot;: null,
                     &quot;consumers&quot;: null,
                     &quot;consumer_associations&quot;: null,
                     &quot;provider_associations&quot;: null
                 },
             ],
             &quot;experimenter_creator_obj&quot;: {
                &quot;experimenter_id&quot;: 29,
                 &quot;first_name&quot;: &quot;Vito&quot;,
                 &quot;last_name&quot;: &quot;Di Benedetto&quot;,
                 &quot;username&quot;: &quot;vito&quot;,
                 &quot;last_login&quot;: &quot;2019-03-08T10:03:42&quot;,
                 &quot;session_experiment&quot;: &quot;uboone&quot;,
                 &quot;session_role&quot;: &quot;analysis&quot;,
                 &quot;root&quot;: false,
                 &quot;exp_expers&quot;: null
             }
         },
     ],
     &quot;last_activity&quot;: &quot;2019-08-20 18:07:02&quot;,
     &quot;msg&quot;: &quot;OK&quot;,
     &quot;data&quot;: {
         &quot;view_active&quot;: &quot;view_active&quot;,
         &quot;view_inactive&quot;: null,
         &quot;view_mine&quot;: 4,
         &quot;view_others&quot;: 4,
         &quot;view_analysis&quot;: null,
         &quot;view_production&quot;: &quot;view_production&quot;,
         &quot;authorized&quot;: [true, true]
     }
}


tag_campaigns (tag, cids, experiment, role=None, test_client=False):


  Apply tag to campaigns whose ids are in “cids” which is a comma-separated list.


update_stage_param_overrides (experiment, campaign_stage, param_overrides=None, test_param_overrides=None, test=None, role=None, configfile=None):


  Lets you set the param overrides on a campaign stage.  These again are a list of pairs of strings, as in the .ini file dump;or a json dump of same.


update_submission (submission_id, jobsub_job_id=None, status=None, project=None, test=None, experiment=None, role=None, configfile=None):


  Update a submission.


uploaded_files_rm (experiment, filename, test=None, role=None, configfile=None):


  Remove an uploaded file.


upload_file (file_name, test=None, experiment=None, role=None, configfile=None):


  Upload a file.


upload_wf (file_name, test=None, experiment=None, configfile=None, replace=False, role=None):


  Upload a campaign .ini file.


Deprecated Methods

update_session_experiment (experiment, test_client=False):

You can now pass experiment and role on all calls.  This will still
set defaults for them if you don&#39;t pass them in.


update_session_role (role, test_client=False):

You can now pass experiment and role on all calls.  This will still
set defaults for them if you don&#39;t pass them in.


campaign_stage_edit (action, campaign_id, ae_stage_name, pc_username, experiment, vo_role, dataset, ae_active, ae_split_type, ae_software_version, ae_completion_type, ae_completion_pct, ae_param_overrides, ae_depends, ae_launch_name, ae_campaign_definition, ae_test_param_overrides, test_client=None, configfile=None) experiment=None, role=None)

campaign_definition_edit (output_file_patterns, launch_script, def_parameter=None, pc_username=None, action=None, name=None, experiment=None, recoveries=None, test_client=False, configfile=None)
campaign_edit (**kwargs):

register_poms_campaign (campaign_name, user=None, experiment=None, version=None, dataset=None, campaign_definition=None, test=None, role=None, configfile=None):

job_type_edit (output_file_patterns, launch_script, def_parameter=None, pc_username=None,

launch_template_edit (action=None, launch_name=None, launch_host=None, user_account=None, launch_setup=None, experiment=None, pc_username=None, test_client=False, role=None, configfile=None)

get_task_id_for (campaign, user=None, command_executed=None, input_dataset=None, parent_task_id=None, task_id=None, test=None, experiment=None, role=None, configfile=None):


  This is the old name for get_submission_id_for().


launch_jobs (campaign, test=None, experiment=None, role=None, configfile=None):


  This is the old call for launch_campaign_stage_jobs

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/client_documentation/">Client Documentation</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Release v4.0.0 Backward Compatibility-----
  About Campaigns
  About Tagging
  About Campaign Editor
  About Campaign Editor and field values from pull-down menu


What You need to know!

As you probably have seen from the Release Notes there has been several changes in this new version.

About Campaigns

The main conceptual change regards the Campaign which translates in technical changes.

Before, the Campaign was an *abstract* concept: a collection of stages which were or not dependent on each other.
People occasionally used to define a Tag to group the stages based on their purpose or they used very long  campaign stages names to indicate they were related to the same workflow; for example:


  exp_prod_mu_100-1257MeV_fixposcontained_fixangle_gen
  exp_prod_mu_100-1257MeV_fixposcontained_fixangle_g4
  exp_prod_mu_100-1257MeV_fixposcontained_fixangle_detsim
  exp_prod_mu_100-1257MeV_fixposcontained_fixangle_reco
  exp_prod_mu_100-1257MeV_fixposcontained_fixangle_ana


In the new release, the Campaign has been introduced as a physical object which contains stages (one or more).
The following is what has been done for this transition:


  
    For a stage that was  standalone  and without a tag, a campaign has been created with the same name as the stage.
  
  For stages that were  standalone  but had a tag, a campaign has been created with the same name as the tag.
    
      This has introduced a problem that has been worked on.
    
  
  For stages which depended on each other  and  had a tag, a campaign has been created with the same name as the tag.
  For stages which depended on each other without a tag, a campaign name has been chosen based on common part in the stage names.


As some problems have been discovered in this process, we will be working with the experiments to improve naming conventions.

One of the very positive aspects of having a campaign, is that you can confine the purpose of the stages in the name of the campaign and use much shorter names for the stages.
So, using the example above, we could have the following:


  Campaign Name:  exp_prod_mu_100-1257MeV_fixposcontained_fixangle
  Campaign Stages:
    
      gen
      g4
      detsim
      reco
      ana
    
  


Since the stages belong to the campaign, you can use same stage names for convenience for another campaign, example:


  Campaign Name: exp_prod_mu_100-2500MeV_fixposcontained_fixangle
  Campaign Stages:
    
      gen
      g4
      detsim
      reco
      ana
    
  


About Tagging

The concept of  a Tag still exists, however it is applied to the Campaign level, not to the stage level.
You can add/remove tags from the Campaigns page.

About Campaign Editor

Since the campaign exists, when it is presented in the GUI Editor it will appear in a gray background oval shape object.
When the conversion was made, we could run into a couple of situations:

Standalone stage: the campaign was created with the same fields and values as the stage. 
At this point you can do the following:


  Modify the stage fields: the new values will belong to the modified stage, campaign default values are not changed.
  Create a new stage: the new stage is created using the campaign default values; when you change the new stage, again changes apply just to the stage, not default.


Campaign with multiple stages: the campaign was created using arbitrarly the ‘most present’ values among the stages.
Again you can proceed and apply the changes you need.

Please remember that the changes will be in effect ONLY after clicking the Save button.

About Campaign Editor and field values from pull-down menu

Besides the stages, in the Campaign Editor drawing board you have the Login setup and the Job type. The ones you see are the one used in the stages.
If you decide to create a new login setup or job type opening a different TAB or window, and you still have the Campaign Editor with the Campaign opened, please remember to refresh the page in order to repopulate the pull down menu and in so doing see the new values.

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/backwards_compatibility/">Release v4.0.0 Backward Compatibility</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Glossary-----
  Campaign
  Campaign Stage
  Experimenter
  Experiment
  Job
  Service
  Job Type
  Submission

This page defines various terms used in POMS, and help links in the application may point here.

Campaign

A Campaign is a collection of stages which define the steps to setup, start and run to achieve the goal of data processing.

Campaign Stage

A high-level group of processing work. It based upon a user/group request to run multiple multi-job
submissions described by a Job Type under a given Role to process a given Dataset with a particular software version.

Experimenter

A person who requests a task, and/or an operator or other person in the system

Experiment

An experiment virtual organization name associated with a request.

Job
An individual batch-system job, part of a given Task’s job submission, which associated with a Campaign.
POMS ignores jobs which are not part of a Campaign. Jobs are considered to be in one of 5 high level
states:


  Idle – The job is waiting to be scheduled somewhere by the batch system
  Running – The job has been started by the batch system, and is still running
  Completed – the job has finished running
  Held – the batch system has stopped the job for some reason (using too much memory, etc)
  Located – the job was not only completed, but its output files have locations in the data handling system.


where the first 4 are the usual states are defined by Condor, and the fifth is peculiar to POMS. Within the Running state, there may be more details logged; i.e. “Running: running user executable” , “Running: copying in files”, etc. where these can be determined from the ifdh joblogs.

Service

A system that we depend on to run jobs, whose status is in some way determinable.

Job Type

(Task Definition/Campaign (layer) Definition)

All the info you need to run a particular category of job – i.e. “how do I launch a NOvA montecarlo job”
or “how do I launch a Minerva calibration keepup job”. This is filled in with information from a given
Campaign to know how to run a submit a given Task.

Submission

(Task)

A specific multi-job launch. It has a specific command line used to launch it, and it may have
output files for whose appearance we await in the data handling system before we declare the task
complete. It has states defined in terms of the jobs it generates as follows:


  Idle – all of its jobs are Idle
  Running – one or more of its jobs are Running
  Completed – all of its jobs are Completed or Declared
  Located – all of its jobs are Located


If another Submission in (another Campaign Layer) needs the output of this one to be launched, it must wait for this task to be in state “Located”
before launching; or if the Submissions are generated with a Draining dataset definition, one waits for the previous
task for this Campaign to complete before launching another.
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/glossary/">Glossary</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Campaign Editor-----
  Overview
  Interacting with the GUI

Overview

The Campaign Editor referred to in several places in the POMS Overview makes use of a dynamic visualization library called vis.js.
Of the several graphic libraries vis.js offers, the Campaign Editor is based on the Network component which allows the user to create the whole campaign structure in a easy-to-use way employing the concept of ‘node’ and ‘edge’.
For our general purpose, the following terminology mapping is used:


  Node –&gt; campaign defaults, campaign stage, login/setup and job type.
  Edge –&gt; dependencies


To demonstrate the use of the Campaign Editor we will use the basic campaign ‘eve_calib’ .
The campaign has been created using the following basic steps:


  From POMS main menu, under Campaign Data click on Campaigns
  From Campaigns page click on Add, assign a name and Save (in our example eve_calib).
  Under Campaigns, find the newly added campaign, eve_calib, and click on the ‘GUI Editor’ icon.


The following page shows the result of the previous actions:



The picture shows the Campaign Editor drawing board showing the basic elements resulted from creating the campaign.
The drawing board has an ‘Edit’ button which will show available actions on the elements:


  Add Edge
  Delete Selected (only shown when an existing element is selected)


It is divided in two sections, the top part where you compose the campaign by adding stages and dependencies, and the bottom part where it shows the login/setup and jobtype elements.

When the campaign is created, it is assigned some default values and a single stage based on a generic login/setup and jobtype templates.
The following picture shows all the forms ‘behind’ each element which are viewable by double clicking on each element.



The picture illustrates how the stage has inherited the defaults for the campaign; by convention, the default values in a stage are shown with an ‘aqua’ color background.
The last two fields in the default and the stage show the assigned login setup and jobtype.

Interacting with the GUI

The GUI offers easy way to add and modify the elements. Let’s briefly describe some.
Basic actions are as follows (mouse based):


  Double left click on an element, example the node eve_calib, will open up a form with the currently stored values which are modifiable.
  Single left click on an element will select it and allow actions on it chosen from the Edit bar.
  Single right click on the node will allow to create another node which will be a child of it created with the campaign default field values.


After opening a box with the information, you can click on it to move it around on the screen as to not cover other objects.
One important point to make right away is that all the changes you will make on the Campaign Editor drawing board will not be saved until you click the Save button.
Let’s see the actions in practice as we add another stage and a dependency to our basic campaign.

Right click on stage0, a box will appear where you will assign the name to the new stage, in our case, stage1.
As you can see from the picture, adding the new stage automatically creates a dependency between the ‘parent’ stage and the ‘child’.



The following picture shows how the definitions for the new stage have been also inherited from the defaults and it also shows the content of the dependency.
To view those, double click on the elements.



You can change the stage definition as you needed: double click on the stage and you can update which ever field. In the example below , the completion percentage has been change.
The picture shows how, after the change, the field background color is no longer aqua to visually show that the value is different from the initial default.



A useful feature: if you change the value of a field in the default values, the change will be propagated to all the stages that use that default field: to do this, change the value in the default, Save and then you will see the changes propagated.

Another interesting point regards changing the login/setup or the Job Type. It is typical that different campaign share the same login setup and/or, for a similar stage, the same job type.
However, for example, if you need to change a field in a job type, you can do that as long as you provide a new name. In this case a new job type will be created automatically.
See the picture below and what happens if you make changes but you don’t change the Job Type name:



Another illustration of changes is in the next picture based on the following steps:


  We added another stage, stage2
  From the pull down menu we picked a new job type, generic_fife_process1
  We want to change the file pattern, so we change the name to generic_fife_process2


When we click OK on the job type box, the Jobtype Update box appears to confirm for which stages you want to apply the change.



When we confirm and save the new campaign will have the following configuration:



With the simple actions described above you can create and modify campaigns as you need.

An interesting situation is when you want to add multiple children from the same parent, example 3 stages from the existing stage1: this can be accomplished by right clicking on parent and when specifying the name add ‘*N’, N being the number of stages you want to create; as usual the children will inherit all the fields from the defaults.
See below where 3 stages were created:



You can make campaigns as complicated as you wish. The following pictures shows another case:



">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/campaign_editor/">Campaign Editor</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="POMS Overview-----
  POMS User Documentation
  Frequently Asked Questions


The Production Operations Management System (POMS) is a project designed to provide  a service to assist production teams and analysis groups of experiments in their MC production and DATA processing. As the quantity of data originated by the running experiments greatly increases, the ability of simplifying the steps in data processing and management has become more and more appealing to the users.

POMS provides a web service interface that enables automated jobs submission on distributed resources according to customers’ requests and subsequent monitoring and recovery of failed submissions, debugging and record keeping.
The ultimate goal is the most efficient utilization of all computing resources available to experiments, while providing a simple and transparent interface between users and the complexity of the grid.

POMS runs behind a web service interface that provides both interactive pages to the users, and a REST interfaces to scripts that interact with it. This means that experiments can use POMS through their web browser to configure and run their production code, or they can use the poms_client and poms_jobsub_wrapper tools to submit jobs through a command line and have POMS tracking, debugging and monitoring them.



POMS User Documentation

For the full documentation please refer to


  POMS User Documentation
  Campaign Editor
  POMS Client Documentation
  Release Notes
  Release v4.0.0 Backward Compatibility - What You need to know


POMS is interfaced to the following systems:


  “Jobsub”: a service that provides support for the job lifecycle enabling the management of jobs on distributed resources, such as the Grid.
  “SAM”: the data handling system, to keep track of files, their meta-data and processing.
  “FIFEmon”: for monitoring.
  “FIFE_UTILS”




The production instance of POMS is at: https://pomsgpvm01.fnal.gov

If new to computing at Fermilab, please read: FIFE Wiki page: “Welcome New Computing Users”

Users’ mailing list : poms_announce@fnal.gov



Frequently Asked Questions




For anything not covered within this documentation, please feel free to reach out to the POMS Admin
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/">POMS Overview</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
        
            
                <li class="searchable-post" data-search-text="-----* TOC
{:toc}

">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/"></a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="Experimenter Guide-----* TOC
{:toc}

The user can find documentation about how to use the service, create their campaigns, launch templates, job types and launch jobs.

* [How to use POMS]({{ site.url }}/docs/experimenters_corner/how_to_use_poms)
* [How to open a SNOW request for POMS]({{ site.url }}/docs/experimenters_corner/how_to_make_snow_request_for_poms)
* [TutorialOutline]({{ site.url }}/docs/experimenters_corner/tutorial_outline)

### Articles/Presentations

* [FIFE Newsletter Article]({{ site.url }}/docs/experimenters_corner/fife_newsletter_article)
* [FIFE Workshop Slides](https://cdcvs.fnal.gov/redmine/documents/1070)


### Useful links

* [Getting more memory in recovery jobs]({{ site.url }}/docs/experimenters_corner/getting_more_memory_in_recovery_jobs)
* [ProtoDUNE]({{ site.url }}/docs/experimenters_corner/protoDUNE)

### Individual Page Help

* [Campaign Layer Info - what do you need to know to add a CampaignLayer]({{ site.url }}/docs/experimenters_corner/campaign_layer_info)
* [Glossary]({{ site.url }}/docs/glossary)

* Help Screens
  * [Calendar Help]({{ site.url }}/docs/experimenters_corner/calendar_help)
  * [Campaign Definition Edit Help]({{ site.url }}/docs/experimenters_corner/editing_job_types)
  * [Campaign Edit Help]({{ site.url }}/docs/experimenters_corner/campaign_edit_help)
    * [Dataset Split Types]({{ site.url }}/docs/experimenters_corner/dataset_split_types)
  * [Campaign Info Help]({{ site.url }}/docs/experimenters_corner/campaign_info_help)
  * [Campaign Layer Info]({{ site.url }}/docs/experimenters_corner/campaign_layer_info)
  * [Campaign Sheet Help]({{ site.url }}/docs/experimenters_corner/campaign_sheet_help)
  * [Campaign Task Files Help]({{ site.url }}/docs/experimenters_corner/campaign_task_files_help)
  * [Campaign Time Bars Help]({{ site.url }}/docs/experimenters_corner/campaign_time_bars_help)
  * [Dashboard Help]({{ site.url }}/docs/experimenters_corner/dashboard_help)
  * [Edit Users Help]({{ site.url }}/docs/experimenters_corner/edit_users_help)
  * [Experiment Edit Help]({{ site.url }}/docs/experimenters_corner/experiment_edit_help)
  * [Job Efficiency Histo Help]({{ site.url }}/docs/experimenters_corner/job_efficiency_histo_help)
  * [Job File Contents Help]({{ site.url }}/docs/experimenters_corner/job_file_contents_help)
  * [Job Table Help]({{ site.url }}/docs/experimenters_corner/job_table_help)
  * [Launch Template Edit Help]({{ site.url }}/docs/experimenters_corner/launch_template_edit_help)
  * [Raw Tables Help]({{ site.url }}/docs/experimenters_corner/raw_tables_help)
  * [Schedule Launch Help]({{ site.url }}/docs/experimenters_corner/schedule_launch_help)
  * [Show Campaigns Help]({{ site.url }}/docs/experimenters_corner/show_campaigns_help)
  * [Triage Job Help]({{ site.url }}/docs/)
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/docs/experimenters_corner/">Experimenter Guide</a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="-----@import &quot;minima&quot;;
">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/assets/main.css"></a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
            
                <li class="searchable-post" data-search-text="-----{% if page.xsl %}{% endif %}Jekyll{{ site.time | date_to_xmlschema }}{{ page.url | absolute_url | xml_escape }}{% assign title = site.title | default: site.name %}{% if page.collection != &quot;posts&quot; %}{% assign collection = page.collection | capitalize %}{% assign title = title | append: &quot; | &quot; | append: collection %}{% endif %}{% if page.category %}{% assign category = page.category | capitalize %}{% assign title = title | append: &quot; | &quot; | append: category %}{% endif %}{% if title %}{{ title | smartify | xml_escape }}{% endif %}{% if site.description %}{{ site.description | xml_escape }}{% endif %}{% if site.author %}{{ site.author.name | default: site.author | xml_escape }}{% if site.author.email %}{{ site.author.email | xml_escape }}{% endif %}{% if site.author.uri %}{{ site.author.uri | xml_escape }}{% endif %}{% endif %}{% if page.tags %}{% assign posts = site.tags[page.tags] %}{% else %}{% assign posts = site[page.collection] %}{% endif %}{% if page.category %}{% assign posts = posts | where: &quot;categories&quot;, page.category %}{% endif %}{% unless site.show_drafts %}{% assign posts = posts | where_exp: &quot;post&quot;, &quot;post.draft != true&quot; %}{% endunless %}{% assign posts = posts | sort: &quot;date&quot; | reverse %}{% assign posts_limit = site.feed.posts_limit | default: 10 %}{% for post in posts limit: posts_limit %}{% assign post_title = post.title | smartify | strip_html | normalize_whitespace | xml_escape %}{{ post_title }}{{ post.date | date_to_xmlschema }}{{ post.last_modified_at | default: post.date | date_to_xmlschema }}{{ post.id | absolute_url | xml_escape }}{% assign excerpt_only = post.feed.excerpt_only | default: site.feed.excerpt_only %}{% unless excerpt_only %}{% endunless %}{% assign post_author = post.author | default: post.authors[0] | default: site.author %}{% assign post_author = site.data.authors[post_author] | default: post_author %}{% assign post_author_email = post_author.email | default: nil %}{% assign post_author_uri = post_author.uri | default: nil %}{% assign post_author_name = post_author.name | default: post_author %}{{ post_author_name | default: &quot;&quot; | xml_escape }}{% if post_author_email %}{{ post_author_email | xml_escape }}{% endif %}{% if post_author_uri %}{{ post_author_uri | xml_escape }}{% endif %}{% if post.category %}{% elsif post.categories %}{% for category in post.categories %}{% endfor %}{% endif %}{% for tag in post.tags %}{% endfor %}{% assign post_summary = post.description | default: post.excerpt %}{% if post_summary and post_summary != empty %}{% endif %}{% assign post_image = post.image.path | default: post.image %}{% if post_image %}{% unless post_image contains &quot;://&quot; %}{% assign post_image = post_image | absolute_url %}{% endunless %}{% endif %}{% endfor %}">
                    <div class="card">
                        <div class="card-header search-results-header">
                            <h4>
                                <a class="search-result-page-title" href="/feed.xml"></a>
                            </h4>
                        </div>
                        <div class="card-body">
                            <ul class="search-instances">
                            </ul>
                        </div>
                    </div>
                </li>
            
        
    </ul>
</div>


  </div>

</article>

        <button id="back-to-top-button"><i class="fas fa-arrow-up"></i></button>
      </div>
    </main>
  </body>
</html>